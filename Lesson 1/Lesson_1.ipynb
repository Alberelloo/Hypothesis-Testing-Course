{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "V_4R2YA10pzJ",
        "FfBlZsai0wFe",
        "bdXlcecncjKP",
        "IAFEk_LnGOL2",
        "fhVWK53A9CRr",
        "fUhlHgHh4qoH",
        "OdOF0MnQ1JC6",
        "OBiPGbgAzzPB",
        "IZ9E0Qm1zzUv",
        "OYaMqzn8y9hX",
        "r_X4PT_ay9lk",
        "9c-pIGz7xLv4",
        "JSHSubLAxMQg",
        "9w88UPfwwRbj",
        "WGH4jNlUwRm4",
        "T5qu_lp0tdUT",
        "6X7x_CsqtfM_",
        "5Zc-DEqr0dMS",
        "0dofwq8UmFaN",
        "TP8g1455mBgE",
        "dL1uS1m6lRPu",
        "iu3BvJosDBxp",
        "NGPHA_yo05aD",
        "jxH5cMfF7wrh",
        "z5V72edZ78ei"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Вводная (необязательная) часть: Статистика в Python"
      ],
      "metadata": {
        "id": "V_4R2YA10pzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Libs"
      ],
      "metadata": {
        "id": "FfBlZsai0wFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # Для численных операций\n",
        "import pandas as pd # Для работы с табличными данными\n",
        "import matplotlib.pyplot as plt # Для построения графиков\n",
        "import seaborn as sns # Для улучшенной визуализации\n",
        "from scipy import stats # Для статистических функций, например, нормального распределения\n",
        "import random # Для случайных операций, в частности для тасования\n",
        "from matplotlib.ticker import FuncFormatter # для форматирования графиков\n",
        "\n",
        "\n",
        "pd.set_option('display.max_rows', 1000)\n",
        "pd.set_option('display.max_columns', 100)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\", font_scale=1.1)\n",
        "palette = sns.color_palette('viridis')\n",
        "plt.rcParams['figure.facecolor'] = 'white'\n",
        "plt.rcParams['axes.grid'] = True\n",
        "plt.rcParams['grid.alpha'] = 0.3"
      ],
      "metadata": {
        "id": "ipDNxaFQGN93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Создаём датафрейм"
      ],
      "metadata": {
        "id": "bdXlcecncjKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Для демонстрации мы сгенерируем небольшой набор данных, как это часто делается для объяснения базовых концепций.\n",
        "\n",
        "np.random.seed(42)\n",
        "n_observations = 10_000\n",
        "\n",
        "data = {\n",
        "    'age': np.random.normal(loc=35, scale=10, size=n_observations).round(2),\n",
        "    'num_children': np.random.poisson(lam=0.5, size=n_observations),\n",
        "    'income': np.random.gamma(shape=2, scale=50000, size=n_observations).round(2)\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Немного корректируем данные, чтобы они были реалистичнее (например, возраст не может быть отрицательным)\n",
        "df['age'] = df['age'].apply(lambda x: max(18, x))\n",
        "df['num_children'] = df['num_children'].apply(lambda x: min(5, x)) # Ограничим количество детей\n",
        "\n",
        "# Добавим одного \"очень богатого\" человека, чтобы показать эффект выбросов\n",
        "df.loc[0, 'income'] = 1_000_000\n",
        "\n",
        "#Базовые возможности Pandas:\n",
        "\n",
        "print(df.head(n=5)) # Отображает первые 5 строк DataFrame.\n",
        "print(f'\\n {\"-\"*25}',df.info()) # Краткая сводка по DataFrame, включая типы данных и количество непустых значений.\n",
        "df.describe() # Генерирует описательную статистику для числовых столбцов."
      ],
      "metadata": {
        "id": "UtL-DmlEcjQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Дискретные и Непрерывные переменные"
      ],
      "metadata": {
        "id": "IAFEk_LnGOL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В работе с данными мы сталкиваемся с двумя основными типами переменных: дискретными и непрерывными. Понимание их различий критично для выбора правильных методов анализа и визуализации.\n",
        "* **Дискретные переменные (Discrete Variables)**: Принимают конечный или счётный набор значений. Например, количество детей (0, 1, 2, 3...). Не может быть \"половины ребёнка\".\n",
        "* **Непрерывные переменные (Continuous Variables)**: Могут принимать любое значение в заданном диапазоне. Например, возраст или доход. Возраст человека можно измерить вплоть до миллисекунд, что делает его по сути непрерывной величиной."
      ],
      "metadata": {
        "id": "l-vptX4SeFlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Анализ дискретных переменных\n",
        "\n",
        "print(\"\\nРаспределение количества детей\")\n",
        "print(df['num_children'].value_counts())\n",
        "print(df['num_children'].value_counts(normalize=True))\n",
        "\n",
        "# Гистограмма для дискретных переменных (визуализация распределения)\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(df['num_children'], kde=True ,discrete=True, stat='probability') # stat='probability' показывает долю\n",
        "plt.title('Гистограмма количества детей (доли)')\n",
        "plt.xlabel('Количество детей')\n",
        "plt.ylabel('Доля')\n",
        "plt.xticks(df['num_children'].unique()) # Устанавливаем метки для каждого значения\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nXpHz8_18cXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Анализ непрерывных переменных\n",
        "\n",
        "print(\"\\nvalue_counts для возраста (неинформативно):\")\n",
        "print(df['age'].value_counts().head())\n",
        "\n",
        "# Гистограмма для непрерывных переменных - разбивает диапазон на интервалы (бины)\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(df['age'], bins=10, kde=True, stat='probability') # kde=True добавляет оценку плотности ядра\n",
        "plt.title('Гистограмма возраста (доли)')\n",
        "plt.xlabel('Возраст')\n",
        "plt.ylabel('Доля')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(df['income'], bins=50, kde=True, stat='probability')\n",
        "plt.title('Гистограмма дохода (доли)')\n",
        "plt.xlabel('Доход')\n",
        "plt.ylabel('Доля')\n",
        "plt.show()\n",
        "\n",
        "# Разбиение непрерывной переменной на категории (бины) с помощью pd.cut\n",
        "df['age_bin'] = pd.cut(df['age'], bins=10, labels=False, include_lowest=True)\n",
        "print(\"\\nРаспределение возраста по 10 бинам:\")\n",
        "print(df['age_bin'].value_counts().sort_index())"
      ],
      "metadata": {
        "id": "-9v9yTeR8pvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Метрики"
      ],
      "metadata": {
        "id": "fhVWK53A9CRr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lncJoOIEF6dx"
      },
      "outputs": [],
      "source": [
        "# 3. Метрики центральной тенденции\n",
        "\n",
        "print(\"\\n3. Метрики центральной тенденции:\")\n",
        "# Среднее (Mean)\n",
        "print(f\"Средний возраст: {df['age'].mean():.2f}\")\n",
        "print(f\"Среднее количество детей: {df['num_children'].mean():.2f}\")\n",
        "print(f\"Средний доход: {df['income'].mean():.2f}\")\n",
        "\n",
        "# Проблема Билла Гейтса: Среднее чувствительно к выбросам [25, 26]\n",
        "salaries = pd.Series([27, 27-29, 29, 30])\n",
        "print(f\"\\nЗарплаты без Билла Гейтса: {salaries.tolist()}\")\n",
        "print(f\"Средняя зарплата без Билла Гейтса: {salaries.mean():.2f}\")\n",
        "bill_gates_salaries = pd.Series([27, 27-29, 29, 30]) # Добавляем выброс\n",
        "print(f\"Зарплаты с Биллом Гейтсом: {bill_gates_salaries.tolist()}\")\n",
        "print(f\"Средняя зарплата с Биллом Гейтсом: {bill_gates_salaries.mean():.2f}\") # Среднее сильно исказилось\n",
        "\n",
        "# Медиана (Median)\n",
        "print(f\"Медианное количество детей: {df['num_children'].median():.2f}\")\n",
        "print(f\"Медианный доход: {df['income'].median():.2f}\")\n",
        "print(f\"Медианная зарплата с Биллом Гейтсом: {bill_gates_salaries.median():.2f}\") # Медиана осталась разумной\n",
        "\n",
        "# Мода (Mode)\n",
        "print(f\"\\nМода количества детей: {df['num_children'].mode().tolist()}\") # Может быть несколько мод\n",
        "print(f\"Мода возраста (для непрерывной, может быть неинформативно): {df['age'].mode().tolist()}\") # Обычно бесполезна для непрерывных\n",
        "\n",
        "# Квантили / Процентили\n",
        "\n",
        "# Значение, ниже которого находится определенный процент наблюдений.\n",
        "print(f\"\\n10-й процентиль дохода: {df['income'].quantile(0.10):.2f}\")\n",
        "print(f\"90-й процентиль дохода: {df['income'].quantile(0.90):.2f}\")\n",
        "\n",
        "# Квартили - это 25-й, 50-й (медиана) и 75-й процентили [41, 42]\n",
        "print(f\"25-й процентиль (Q1) дохода: {df['income'].quantile(0.25):.2f}\")\n",
        "print(f\"75-й процентиль (Q3) дохода: {df['income'].quantile(0.75):.2f}\")\n",
        "\n",
        "# 4. Метрики разброса\n",
        "print(\"\\n4. Метрики разброса:\")\n",
        "# Стандартное отклонение (Standard Deviation, STD)\n",
        "print(f\"Стандартное отклонение дохода: {df['income'].std():.2f}\")\n",
        "\n",
        "# Среднее абсолютное отклонение (Mean Absolute Deviation, MAD)\n",
        "income_mean = df['income'].mean()\n",
        "mad_income = np.mean(np.abs(df['income'] - income_mean))\n",
        "print(f\"Среднее абсолютное отклонение дохода (MAD): {mad_income:.2f}\")\n",
        "\n",
        "# 5. Сводная статистика (describe)\n",
        "print(\"\\n5. Сводная статистика (describe):\")\n",
        "print(df['income'].describe()) # Включает count, mean, std, min, 25%, 50%, 75%, max"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Визуализации"
      ],
      "metadata": {
        "id": "fUhlHgHh4qoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create age groups (but keep original for correlation)\n",
        "df['age_group_label'] = pd.qcut(df['age'], q=5, labels=[f'Q{i+1}\\n({q.left:.0f}-{q.right:.0f} yrs)'\n",
        "                              for i, q in enumerate(pd.qcut(df['age'], q=5).cat.categories)])\n",
        "df['age_group'] = pd.qcut(df['age'], q=5)\n",
        "\n",
        "\n",
        "# Custom formatter for currency\n",
        "def currency_formatter(x, pos):\n",
        "    return f'{x/1000:,.0f}k ₽' if x >= 10000 else f'{x:,.0f} ₽'\n",
        "\n",
        "# Create figure with subplots\n",
        "fig, axes = plt.subplots(3, 2, figsize=(14*2, 6*3))  # 3 rows, 2 columns\n",
        "axes = axes.flatten()\n",
        "\n",
        "# ---------- 1. Enhanced Boxplot ----------\n",
        "sns.boxplot(\n",
        "    y='income',\n",
        "    data=df,\n",
        "    width=0.3,\n",
        "    fliersize=4,\n",
        "    linewidth=1.8,\n",
        "    color=palette[2],\n",
        "    showmeans=True,\n",
        "    meanprops={\"marker\":\"o\", \"markerfacecolor\":\"white\", \"markeredgecolor\":\"crimson\", \"markersize\":\"8\"},\n",
        "    ax=axes[0]\n",
        ")\n",
        "axes[0].set_title('1. Income Distribution Analysis', pad=20, fontweight='bold', fontsize=14)\n",
        "axes[0].set_ylabel('Monthly Income', labelpad=10)\n",
        "axes[0].yaxis.set_major_formatter(FuncFormatter(currency_formatter))\n",
        "\n",
        "# ---------- 2. Enhanced Scatter Plot with Regression ----------\n",
        "sns.scatterplot(\n",
        "    x='age',\n",
        "    y='income',\n",
        "    hue='num_children',\n",
        "    data=df,\n",
        "    alpha=0.7,\n",
        "    s=60,\n",
        "    palette='viridis',\n",
        "    edgecolor='white',\n",
        "    linewidth=0.3,\n",
        "    ax=axes[1]\n",
        ")\n",
        "\n",
        "# Regression line\n",
        "sns.regplot(\n",
        "    x='age',\n",
        "    y='income',\n",
        "    data=df,\n",
        "    scatter=False,\n",
        "    ax=axes[1],\n",
        "    color='crimson',\n",
        "    line_kws={'linewidth':2.5, 'linestyle':'--'}\n",
        ")\n",
        "\n",
        "# Correlation annotation\n",
        "r = df['age'].corr(df['income'])\n",
        "axes[1].annotate(\n",
        "    fr'Pearson $r={r:.2f}$',\n",
        "    xy=(0.05, 0.95),\n",
        "    xycoords='axes fraction',\n",
        "    fontsize=12,\n",
        "    fontweight='bold',\n",
        "    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
        "    color='crimson',\n",
        "    ha='left',\n",
        "    va='top'\n",
        ")\n",
        "\n",
        "axes[1].set_title('2. Income vs Age with Family Size', pad=20, fontweight='bold', fontsize=14)\n",
        "axes[1].set_xlabel('Age (years)', labelpad=10)\n",
        "axes[1].set_ylabel('Monthly Income', labelpad=10)\n",
        "axes[1].yaxis.set_major_formatter(FuncFormatter(currency_formatter))\n",
        "axes[1].legend(title='Children', bbox_to_anchor=(1, 1))\n",
        "\n",
        "# ---------- 3. Enhanced Barplot with Age Quantiles ----------\n",
        "medians = df.groupby('age_group_label')['income'].median().reset_index()\n",
        "\n",
        "sns.barplot(\n",
        "    x='age_group_label',\n",
        "    y='income',\n",
        "    data=medians,\n",
        "    palette='viridis',\n",
        "    edgecolor='black',\n",
        "    linewidth=1,\n",
        "    ax=axes[2]\n",
        ")\n",
        "\n",
        "# Add value labels\n",
        "for p in axes[2].patches:\n",
        "    axes[2].annotate(\n",
        "        f\"{p.get_height()/1000:,.1f}k\",\n",
        "        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "        ha='center', va='center', xytext=(0, 10),\n",
        "        textcoords='offset points',\n",
        "        fontsize=10,\n",
        "        fontweight='bold'\n",
        "    )\n",
        "\n",
        "axes[2].set_title('3. Median Income by Age Quintiles', pad=20, fontweight='bold', fontsize=14)\n",
        "axes[2].set_xlabel('Age Groups (Quintiles)', labelpad=10)\n",
        "axes[2].set_ylabel('Median Income', labelpad=10)\n",
        "axes[2].yaxis.set_major_formatter(FuncFormatter(currency_formatter))\n",
        "\n",
        "# ---------- 4. Histogram with KDE ----------\n",
        "sns.histplot(\n",
        "    data=df,\n",
        "    x='income',\n",
        "    bins=30,\n",
        "    kde=True,\n",
        "    color=palette[3],\n",
        "    edgecolor='white',\n",
        "    linewidth=0.5,\n",
        "    alpha=0.7,\n",
        "    ax=axes[3]\n",
        ")\n",
        "\n",
        "axes[3].set_title('4. Income Distribution with Density Curve', pad=20, fontweight='bold', fontsize=14)\n",
        "axes[3].set_xlabel('Monthly Income', labelpad=10)\n",
        "axes[3].set_ylabel('Count', labelpad=10)\n",
        "axes[3].xaxis.set_major_formatter(FuncFormatter(currency_formatter))\n",
        "\n",
        "# ---------- 5. Violin Plot of Income by Number of Children ----------\n",
        "sns.violinplot(\n",
        "    x='num_children',\n",
        "    y='income',\n",
        "    data=df,\n",
        "    palette='viridis',\n",
        "    inner='quartile',\n",
        "    linewidth=1.5,\n",
        "    saturation=0.8,\n",
        "    ax=axes[4]\n",
        ")\n",
        "\n",
        "axes[4].set_title('5. Income Distribution by Number of Children', pad=20, fontweight='bold', fontsize=14)\n",
        "axes[4].set_xlabel('Number of Children', labelpad=10)\n",
        "axes[4].set_ylabel('Monthly Income', labelpad=10)\n",
        "axes[4].yaxis.set_major_formatter(FuncFormatter(currency_formatter))\n",
        "\n",
        "# ---------- 6. Heatmap of Correlations (using original numerical data) ----------\n",
        "corr_df = df[['age', 'num_children', 'income']].corr()\n",
        "mask = np.triu(np.ones_like(corr_df, dtype=bool))\n",
        "sns.heatmap(\n",
        "    corr_df,\n",
        "    mask=mask,\n",
        "    annot=True,\n",
        "    cmap='viridis',\n",
        "    vmin=-1,\n",
        "    vmax=1,\n",
        "    center=0,\n",
        "    square=True,\n",
        "    linewidths=0.5,\n",
        "    cbar_kws={\"shrink\": 0.8},\n",
        "    annot_kws={\"size\": 12},\n",
        "    ax=axes[5]\n",
        ")\n",
        "axes[5].set_title('6. Feature Correlation Matrix', pad=20, fontweight='bold', fontsize=14)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout(pad=3.0)\n",
        "plt.show()\n",
        "\n",
        "# ---------- 7. Pairplot (shown separately due to different nature) ----------\n",
        "print(\"\\nAdditional Pairplot Visualization:\")\n",
        "g = sns.pairplot(\n",
        "    df[['age', 'num_children', 'income']],\n",
        "    diag_kind='kde',\n",
        "    plot_kws={'alpha':0.6, 's':40, 'edgecolor':'white', 'linewidth':0.3},\n",
        "    diag_kws={'fill':True, 'alpha':0.5, 'linewidth':1.5},\n",
        "    corner=True,\n",
        "    palette='viridis',\n",
        "    height=3  # Smaller individual plots for pairplot\n",
        ")\n",
        "g.fig.suptitle('Multivariate Relationships', y=1.02, fontweight='bold', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gf7CoFW24qyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Задачки"
      ],
      "metadata": {
        "id": "OdOF0MnQ1JC6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Оценить вероятность выпадения 6 на игральном кубике"
      ],
      "metadata": {
        "id": "OBiPGbgAzzPB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Решение"
      ],
      "metadata": {
        "id": "IZ9E0Qm1zzUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dice_faces = list(range(7)) # Грани кубика\n",
        "n_rolls = 100_000 # Количество бросков для симуляции\n",
        "\n",
        "# Выполняем броски\n",
        "rolls = np.random.choice(dice_faces, size=n_rolls)\n",
        "\n",
        "# Оцениваем вероятность выпадения шестерки\n",
        "prob_six_simulated = np.mean(rolls == 6)\n",
        "print(f\"Оценка вероятности выпадения шестерки (симуляция): {prob_six_simulated:.4f}\")"
      ],
      "metadata": {
        "id": "nA7OXx8EzzhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. Парадокс дней рождения\n",
        "\n",
        "Определить вероятность того, что в группе из 23 человек у двух людей совпадет день рождения."
      ],
      "metadata": {
        "id": "OYaMqzn8y9hX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Решение"
      ],
      "metadata": {
        "id": "r_X4PT_ay9lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_people = 23 # Количество человек в группе\n",
        "n_simulations_bd = 10000 # Количество симуляций групп\n",
        "n_days_in_year = 365 # Количество дней в году (игнорируем високосный год)\n",
        "\n",
        "coincidences = []\n",
        "for _ in range(n_simulations_bd):\n",
        "    # Генерируем дни рождения для n_people в диапазоне n_days_in_year с возвращением\n",
        "    birthdays = np.random.randint(0, n_days_in_year, n_people)\n",
        "    # Проверяем, есть ли совпадения (т.е. количество уникальных дней рождения меньше, чем количество людей)\n",
        "    has_coincidence = len(np.unique(birthdays)) < n_people\n",
        "    coincidences.append(has_coincidence)\n",
        "\n",
        "prob_coincidence_simulated = np.mean(coincidences)\n",
        "print(f\"Оценка вероятности совпадения дней рождения в группе из {n_people} человек: {prob_coincidence_simulated:.4f}\")"
      ],
      "metadata": {
        "id": "Zpus_QRxy9xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Задача об экзамене\n",
        "\n",
        "Студент выучил 20 билетов из 30. Когда ему выгоднее идти первым или вторым?"
      ],
      "metadata": {
        "id": "9c-pIGz7xLv4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Решение"
      ],
      "metadata": {
        "id": "JSHSubLAxMQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_tickets = 30\n",
        "learned_tickets_count = 20\n",
        "learned_tickets = set(range(1, learned_tickets_count + 1)) # Билеты, которые знает студент (допустим 1-20)\n",
        "all_tickets = list(range(1, total_tickets + 1)) # Все билеты\n",
        "\n",
        "n_exams = 100_000 # Количество симуляций экзаменов\n",
        "\n",
        "# Вариант 1: Студент идет первым\n",
        "first_student_success = []\n",
        "for _ in tqdm(range(n_exams), desc='Считаем первый случай'):\n",
        "    shuffled_tickets = random.sample(all_tickets, total_tickets) # Перемешиваем билеты\n",
        "    pulled_ticket = shuffled_tickets[0] # Первый билет\n",
        "    first_student_success.append(pulled_ticket in learned_tickets)\n",
        "prob_first_student = np.mean(first_student_success)\n",
        "print(f\"Вероятность вытянуть выученный билет, если студент идет первым: {prob_first_student:.4f}\")\n",
        "\n",
        "# Вариант 2: Студент идет вторым\n",
        "second_student_success = []\n",
        "for _ in tqdm(range(n_exams), desc='Считаем второй случай'):\n",
        "    shuffled_tickets = random.sample(all_tickets, total_tickets) # Перемешиваем билеты\n",
        "    # Первый билет откладывается, поэтому второй студент выбирает из оставшихся\n",
        "    pulled_ticket_second_person = shuffled_tickets[1] # Второй билет\n",
        "    second_student_success.append(pulled_ticket_second_person in learned_tickets)\n",
        "prob_second_student = np.mean(second_student_success)\n",
        "print(f\"Вероятность вытянуть выученный билет, если студент идет вторым: {prob_second_student:.4f}\")"
      ],
      "metadata": {
        "id": "wHjXeyXSxMak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 4. Задача о такси\n",
        "\n",
        "Зеленые такси: 85%, Синие такси: 15%. Свидетель верно определяет цвет в 80% случаев.\n",
        "Какова вероятность, что такси действительно синее, если свидетель сказал, что оно синее?"
      ],
      "metadata": {
        "id": "9w88UPfwwRbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Решение"
      ],
      "metadata": {
        "id": "WGH4jNlUwRm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_incidents = 100_000 # Количество симуляций инцидентов\n",
        "\n",
        "actual_colors = []\n",
        "witness_statements = []\n",
        "\n",
        "for _ in range(n_incidents):\n",
        "    # Генерируем реальный цвет такси: 15% синих (1), 85% зеленых (0)\n",
        "    actual_taxi_color = np.random.choice([0,1], p=[0.85, 0.15]) # 0 - зеленое, 1 - синее\n",
        "    actual_colors.append(actual_taxi_color)\n",
        "\n",
        "    # Моделируем показания свидетеля\n",
        "    if np.random.rand() < 0.8: # Свидетель верно определяет цвет в 80% случаев\n",
        "        witness_says = actual_taxi_color\n",
        "    else: # Ошибается в 20% случаев\n",
        "        witness_says = 1 - actual_taxi_color # Говорит противоположный цвет\n",
        "    witness_statements.append(witness_says)\n",
        "\n",
        "# Создаем DataFrame для анализа\n",
        "taxi_df = pd.DataFrame({'actual_color': actual_colors, 'witness_says': witness_statements})\n",
        "\n",
        "# Фильтруем случаи, когда свидетель сказал, что такси синее (witness_says == 1)\n",
        "witness_said_blue = taxi_df[taxi_df['witness_says'] == 1]\n",
        "# Из этих случаев, какая доля была реально синей (actual_color == 1)\n",
        "prob_actual_blue_given_witness_blue = np.mean(witness_said_blue['actual_color'] == 1)\n",
        "\n",
        "print(f\"Вероятность того, что такси действительно синее, если свидетель сказал, что оно синее: {prob_actual_blue_given_witness_blue:.4f}\")"
      ],
      "metadata": {
        "id": "BhPx7YMIwWtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 5. Задача о русской рулетке\n",
        "\n",
        "Револьвер с 6 гнездами, 2 патрона подряд. Первый игрок крутит барабан и остается жив. Твоя очередь.\n",
        "Что выгоднее: покрутить барабан перед выстрелом или сразу выстрелить?"
      ],
      "metadata": {
        "id": "T5qu_lp0tdUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Решение"
      ],
      "metadata": {
        "id": "6X7x_CsqtfM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rotate_chamber(chamber):\n",
        "    \"\"\"\n",
        "    Сдвигает барабан на одну позицию вперёд (как при следующем\n",
        "    нажатии на спуск без дополнительного вращения).\n",
        "    \"\"\"\n",
        "    return chamber[1:] + chamber[:1]\n",
        "\n",
        "def spin_chamber(chamber):\n",
        "    \"\"\"\n",
        "    Вращает барабан на случайное число позиций.\n",
        "    \"\"\"\n",
        "    k = random.randint(0, len(chamber) - 1)\n",
        "    return chamber[k:] + chamber[:k]\n",
        "\n",
        "\n",
        "# — — — Главная функция симуляции — — —\n",
        "def simulate(n_games=1_000_000, spin_second=True):\n",
        "    \"\"\"\n",
        "    Возвращает условную вероятность смерти второго игрока,\n",
        "    если первый игрок выжил.\n",
        "\n",
        "    spin_second = True  -> второй игрок снова крутит барабан\n",
        "    spin_second = False -> второй игрок НЕ крутит барабан\n",
        "    \"\"\"\n",
        "    deaths, trials = 0, 0\n",
        "\n",
        "    for _ in tqdm(range(n_games)):\n",
        "\n",
        "\n",
        "        chamber = [1, 1, 0, 0, 0, 0] # два подряд идущих патрона\n",
        "\n",
        "        chamber = spin_chamber(chamber) # первый игрок крутит барабан и стреляет\n",
        "        if chamber[0] == 1:                # первый погиб – нас не интересует -> начинаем новую партию\n",
        "            continue\n",
        "\n",
        "        # первый выжил, учитываем такую партию\n",
        "        trials += 1\n",
        "\n",
        "        # после выстрела барабан переходит к следующей камере\n",
        "        chamber = rotate_chamber(chamber)\n",
        "\n",
        "        # решение второго игрока\n",
        "        if spin_second:\n",
        "            chamber = spin_chamber(chamber)\n",
        "\n",
        "        if chamber[0] == 1: # выстрел второго игрока\n",
        "            deaths += 1\n",
        "\n",
        "    return deaths / trials\n",
        "\n",
        "\n",
        "N = 1_000_000   # число условных партий\n",
        "\n",
        "p_spin     = simulate(N, spin_second=True)\n",
        "p_no_spin  = simulate(N, spin_second=False)\n",
        "\n",
        "print(f\"\\nВероятность смерти, если ПОВТОРНО крутить барабан : {p_spin:.4f}\")\n",
        "print(f\"Вероятность смерти, если НЕ крутить барабан      : {p_no_spin:.4f}\")"
      ],
      "metadata": {
        "id": "LoAFEHjJsW_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Основная часть: Бутстреп (Bootstrap)"
      ],
      "metadata": {
        "id": "5Zc-DEqr0dMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Бутстреп (bootstrap)** – это мощный статистический метод, позволяющий оценивать стандартные отклонения, строить доверительные интервалы и проверять гипотезы для произвольных статистических функционалов. Он особенно незаменим в ситуациях, когда нет простой теоретической формулы для оценки стандартного отклонения метрики, например, для квантилей, или когда условия применимости классических статистических теорем (таких как Центральная Предельная Теорема) не выполняются или размер выборки (N) недостаточен для хорошей аппроксимации распределения.\n",
        "\n",
        "Классическая статистика часто опирается на теоремы, которые требуют идеальных условий, таких как бесконечно большой размер выборки (N стремится к бесконечности) или конкретные свойства распределения данных (например, нормальность, гомоскедастичность). Однако в реальной жизни эти идеальные условия часто не выполняются, N может быть недостаточно велико, или для некоторых сложных характеристик (таких как медиана, квантили, или коэффициенты в сложных моделях) просто не существует готовых теоретических формул для стандартных ошибок. Бутстреп приходит на помощь именно в таких случаях.\n",
        "\n",
        "**Основной принцип** бутстрепа заключается в том, что вместо того, чтобы брать данные из истинного, но неизвестного распределения, мы используем эмпирическую функцию распределения (ЭФР), построенную на основе имеющейся выборки, как ее оценку. ЭФР является несмещенной оценкой и сходится к истинной функции распределения при увеличении размера выборки."
      ],
      "metadata": {
        "id": "OlknELZ7HkzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Эмпирическая Функция Распределения (ЭФР)"
      ],
      "metadata": {
        "id": "0dofwq8UmFaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ЭФР (Empirical Distribution Function)** — это оценка истинной функции распределения, которая получается из имеющейся выборки. Если у нас есть выборка из $n$ независимых и одинаково распределенных (i.i.d.) случайных величин $X_1, X_2, \\ldots, X_n$, то ЭФР $F_n(x)$ определяется как доля наблюдений в выборке, которые меньше или равны $x$: $$ F_n(x) = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{1}\\left[{X_i \\le x}\\right] $$где $\\mathbf{1}\\left[{X_i \\le x}\\right]$ — это индикаторная функция, равная 1, если $X_i \\le x$, и 0 в противном случае. По сути, ЭФР — это функция распределения дискретной случайной величины, где каждому наблюдению $X_i$ из исходной выборки присваивается вероятность $1/n$."
      ],
      "metadata": {
        "id": "Lo5Kh9_9Gbhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "def plot_ecdf(values: np.ndarray, label: str, xlim: list, color: str = None) -> None:\n",
        "    \"\"\"\n",
        "    Plot empirical cumulative distribution function (ECDF).\n",
        "\n",
        "    Args:\n",
        "        values: Array of values from distribution\n",
        "        label: Label for graph legend\n",
        "        xlim: List with min and max values to limit x axis\n",
        "        color: Color for the ECDF plot\n",
        "    \"\"\"\n",
        "    X_ = np.sort(np.unique(values))\n",
        "    Y_ = np.array([np.mean(values <= x) for x in X_])\n",
        "\n",
        "    # Create step points for ECDF\n",
        "    X = np.concatenate([[xlim[0]], np.repeat(X_, 2), [xlim[1]]])\n",
        "    Y = np.concatenate([[0, 0], np.repeat(Y_, 2)])\n",
        "\n",
        "    plt.plot(X, Y, label=label, color=color, linewidth=2)\n",
        "\n",
        "# Parameters\n",
        "np.random.seed(42)  # For reproducibility\n",
        "sample_sizes = [20, 200, 2000]\n",
        "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
        "x_limits = [-3.5, 3.5]\n",
        "\n",
        "# Generate data and plot ECDFs\n",
        "plt.figure(figsize=(16, 6), dpi=100)\n",
        "\n",
        "for size, color in zip(sample_sizes, colors):\n",
        "    values = np.random.normal(0, 1, size=size)\n",
        "    plot_ecdf(values, f'n = {size}', x_limits, color)\n",
        "\n",
        "# Plot theoretical CDF\n",
        "X = np.linspace(x_limits[0], x_limits[1], 1000)\n",
        "Y = stats.norm.cdf(X)\n",
        "plt.plot(X, Y, '--', color='black', label='Theoretical CDF', linewidth=2)\n",
        "\n",
        "# Customize plot\n",
        "plt.title('Empirical vs Theoretical CDF\\nStandard Normal Distribution',\n",
        "          fontsize=14, pad=20)\n",
        "plt.xlabel('Value', fontsize=12)\n",
        "plt.ylabel('Cumulative Probability', fontsize=12)\n",
        "plt.legend(fontsize=10, framealpha=1)\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "# Adjust ticks and layout\n",
        "plt.xticks(np.arange(x_limits[0], x_limits[1]+0.5, 0.5))\n",
        "plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sMhHp7OSHyG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "На графике видно, что при увеличении размера выборки ЭФР лучше приближает истинную функцию распределения. Если увеличить размер выборки до нескольких тысяч, то ЭФР визуально будет сложно отличить от истинной функции распределения.\n",
        "\n",
        "На деле же ЭФР является несмещённой оценкой и сходится к истинной ФР при увеличении размера выборки.\n",
        "\n",
        "**[Теорема Гливенко-Кантелли](https://ru.wikipedia.org/wiki/Теорема_Гливенко_—_Кантелли)**:\n",
        "\n",
        "\n",
        "Пусть $X_1, \\ldots, X_n, \\ldots$ - бесконечная выборка из распределения, задаваемого функцией распределения $F$. Пусть $\\hat{F}$ - выборочная функция распределения, построенная на первых $n$ элементах выборки. Тогда\n",
        "\n",
        "$$\n",
        "\\lim_{n\\to\\infty} \\sup_{x\\in\\mathbb{R}} \\left|\\hat{F}(x) - F(x)\\right| = 0 \\quad \\text{почти наверное}\n",
        "$$\n",
        "\n",
        "Так как нам известно, что ЭФР \"хорошо\" приближает истинную ФР, давайте генерировать данные из неё и строить неизвестные оценки метрик и доверительных интервалов."
      ],
      "metadata": {
        "id": "x8GkdlvqKZbI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Наивный Бутстреп"
      ],
      "metadata": {
        "id": "TP8g1455mBgE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Наивный бутстреп** — это самый базовый и широко используемый вариант бутстрепа. Он используется для оценки стандартного отклонения произвольной статистики и построения доверительных интервалов, особенно когда нет простой аналитической формулы для этих величин.\n",
        "\n",
        "**Для чего используется:** Предположим, мы хотим оценить стандартное отклонение 90% квантиля времени доставки заказа. Для среднего времени доставки есть простая формула стандартного отклонения, но для квантилей такой универсальной формулы нет. Наивный бутстреп позволяет обойти это ограничение.\n",
        "\n",
        "**Алгоритм:**\n",
        "1. Сгенерировать бутстреп-выборку\n",
        "  \n",
        "  Выбрать $n$ элементов из исходной выборки $X_1, \\ldots, X_n$ случайным образом с возвращением. Это эквивалентно генерации подвыборки размера $n$ из ЭФР. Каждый элемент исходной выборки имеет вероятность $\\frac{1}{n}$ быть выбранным.\n",
        "2. Вычислить статистику\n",
        "  \n",
        "  Посчитать интересующую статистику $S$ для этой бутстреп-выборки.\n",
        "3. Повторить шаги 1 и 2\n",
        "\n",
        "  Повторить шаги 1 и 2 большое количество раз (рекомендуется от 1000 до 10000 раз), получая $B$ значений статистики $S^*_1, \\ldots, S^*_B$.\n",
        "___\n",
        "\n",
        "**Важные замечания:**\n",
        "1. Сэмплинг должен быть обязательно с повторениями\n",
        "2. Количество сэмплингов должно быть довольно большим, чтобы эмпирическая функция распределения успела сойтись с теоретической и дать несмещенную оценку статистики\n",
        "3. Бутстрапированная статистика должна считаться именно на n элементах выборки, чтобы дисперсия оцениваемой статистики совпадала с бутстрапированной  \n",
        "4. Посчитать стандартное отклонение и доверительные интервалы (CI)\n",
        "___\n",
        "\n",
        "**Выводы:**\n",
        "\n",
        "* **Оценка стандартного отклонения**: Стандартное отклонение статистики можно оценить как стандартное отклонение набора бутстреп-значений $S^*_1, \\ldots, S^*_B$:\n",
        "\n",
        "  $$\n",
        "  \\text{se}(S) \\approx \\text{std}(S^*_1, \\ldots, S^*_B)\n",
        "  $$\n",
        "\n",
        "* **Доверительный интервал**: Есть несколько вариантов построения доверительных интервалов с помощью наивного бутстрепа\n",
        "\n",
        "  * **Перцентильный доверительный интервал**\n",
        "  \n",
        "  Для построения $100\\times (1-\\alpha)%$ доверительного интервала (CI) на основе перцентильного метода, необходимо отбросить $\\alpha/2$ процентов самых маленьких и $\\alpha/2$ процентов самых больших значений из отсортированного списка бутстреп-статистик.\n",
        "$$\n",
        "  \\text{CI} = \\left[ S^*_{(\\alpha/2 \\cdot B)} \\text{ ; } S^*_{( (1-\\alpha/2) \\cdot B )} \\right]\n",
        "  \\quad \\text{где } S^*{(k)} — \\text{k-е значение в отсортированном списке бутстреп-статистик}\n",
        "$$\n",
        "\n",
        "  Это хорошо работает, когда распределение статистики симметрично. В случае несимметричных распределений, нормальный доверительный интервал (см. ниже) может давать некорректные результаты, например, границы интервала могут выходить за пределы допустимых значений.\n",
        "\n",
        "  * **Нормальный Доверительный Интервал**\n",
        "  \n",
        "  Нормальный доверительный интервал основан на предположении, что распределение статистики приблизительно нормально, особенно когда данных много (когда такое можно предполагать ?). Для $100\\times (1-\\alpha)%$ доверительного интервала, нормальный CI вычисляется как: $$ \\text{CI} = \\left[ \\hat{S} - z_{1-\\alpha/2} \\cdot \\text{se}(S) \\text{ ; } \\hat{S} + z_{1-\\alpha/2} \\cdot \\text{se}(S) \\right] $$ где:\n",
        "  \n",
        "  * $\\hat{S}$ — точечная оценка статистики по исходным данным.\n",
        "  * $\\text{se}(S)$ — стандартное отклонение оценки статистики, полученное с помощью бутстрепа.\n",
        "  * $z_{1-\\alpha/2}$ — квантиль стандартного нормального распределения для заданного уровня значимости $\\alpha$.\n",
        "\n",
        "  Этот метод хорошо работает, когда распределение статистики близко к нормальному и симметричному. Если распределение несимметрично, нормальный CI может давать нереалистичные границы (например, отрицательные значения для изначально положительных метрик).\n",
        "\n",
        "  * **Центральный (Pivotal) Доверительный Интервал**\n",
        "\n",
        "  Центральный (пивотальный) доверительный интервал имеет строгое математическое обоснование, хотя на первый взгляд может показаться нелогичным. Он основан на распределении разностей между точечной оценкой статистики и её бутстреп-реализациями.\n",
        "\n",
        "  Для $100 \\times (1-\\alpha)\\%$ доверительного интервала, центральный CI вычисляется как:\n",
        "\n",
        "  $$\n",
        "  \\text{CI} = \\left[ 2\\hat{S} - S^*_{((1-\\alpha/2) \\cdot B)}, 2\\hat{S} - S^*_{(\\alpha/2 \\cdot B)} \\right]\n",
        "  $$\n",
        "\n",
        "  где:\n",
        "  * $\\hat{S}$ — точечная оценка статистики по исходным данным\n",
        "  * $S^*_{(k)}$ — $k$-е значение в отсортированном списке бутстреп-статистик\n",
        "\n",
        "  Этот интервал может быть смещен в сторону с нулевой плотностью для асимметричных распределений, что иногда интерпретируется как перестраховка при неполной информации о распределении.\n",
        "\n",
        "\n",
        "\n",
        "**Преимущества и Недостатки вариации бутстрапа:**\n",
        "\n",
        "* **Универсальность:** Позволяет оценивать свойства распределений практически любых статистик.\n",
        "* **Простота:** Не требует аналитических формул для стандартных ошибок.\n",
        "* **Вычислительная затратность:** Основной недостаток — это вычислительно трудоемкая процедура, которая может занимать много времени при больших объемах данных.\n",
        "\n",
        "**Предположения:**\n",
        "\n",
        "1. Предполагается, что исходные данные являются независимыми и одинаково распределенными (i.i.d.). Если данные зависимы или имеют сложную природу, бутстреп может давать плохие приближения истинного распределения, если это не учитывать при генерации подвыборок. (если интересно подробнее это узнать, то можно посмотреть на [MCMC алгоритмы сэмплирования](https://ru.wikipedia.org/wiki/Марковская_цепь_Монте-Карло))\n",
        "2. **Размер N:** Хотя бутстреп помогает при недостаточно большом N для классических методов, ему все равно требуется достаточно большое N для получения точных результатов."
      ],
      "metadata": {
        "id": "xj6SoUaCNjh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ======================\n",
        "# 1. Функции для расчета CI\n",
        "# ======================\n",
        "\n",
        "def calculate_standard_error(bootstrap_stats):\n",
        "    \"\"\"Вычисляет стандартную ошибку по бутстреп-статистикам.\"\"\"\n",
        "    return np.std(bootstrap_stats, ddof=1)\n",
        "\n",
        "def get_normal_ci(bootstrap_stats, point_estimate, alpha):\n",
        "    \"\"\"Строит нормальный доверительный интервал.\"\"\"\n",
        "    z = stats.norm.ppf(1 - alpha / 2)\n",
        "    se = calculate_standard_error(bootstrap_stats)\n",
        "    left = point_estimate - z * se\n",
        "    right = point_estimate + z * se\n",
        "    return left, right\n",
        "\n",
        "def get_percentile_ci(bootstrap_stats, alpha):\n",
        "    \"\"\"Строит перцентильный доверительный интервал.\"\"\"\n",
        "    left, right = np.quantile(bootstrap_stats, [alpha / 2, 1 - alpha / 2])\n",
        "    return left, right\n",
        "\n",
        "def get_pivotal_ci(bootstrap_stats, point_estimate, alpha):\n",
        "    \"\"\"Строит центральный (пивотальный) доверительный интервал.\"\"\"\n",
        "    left = 2 * point_estimate - np.quantile(bootstrap_stats, 1 - alpha / 2)\n",
        "    right = 2 * point_estimate - np.quantile(bootstrap_stats, alpha / 2)\n",
        "    return left, right\n",
        "\n",
        "# ======================\n",
        "# 2. Подготовка данных\n",
        "# ======================\n",
        "np.random.seed(42)\n",
        "n = 1000\n",
        "mean_delivery, std_delivery = 90, 20\n",
        "values = np.clip(np.random.normal(mean_delivery, std_delivery, n), 0, None)\n",
        "\n",
        "# Точечная оценка\n",
        "quantile_estimate = np.quantile(values, 0.9)\n",
        "\n",
        "# Параметры бутстрепа\n",
        "B = 10000\n",
        "alpha = 0.05\n",
        "confidence_level = 100 * (1 - alpha)\n",
        "\n",
        "# Генерация бутстреп-статистик\n",
        "bootstrap_quantiles = np.array([\n",
        "    np.quantile(np.random.choice(values, n, replace=True), 0.9)\n",
        "    for _ in tqdm(range(B), desc='Генерация бутстреп-выборок')\n",
        "])\n",
        "\n",
        "# Расчет стандартной ошибки\n",
        "std_error = calculate_standard_error(bootstrap_quantiles)\n",
        "\n",
        "# ======================\n",
        "# 3. Расчет доверительных интервалов\n",
        "# ======================\n",
        "normal_ci = get_normal_ci(bootstrap_quantiles, quantile_estimate, alpha)\n",
        "percentile_ci = get_percentile_ci(bootstrap_quantiles, alpha)\n",
        "pivotal_ci = get_pivotal_ci(bootstrap_quantiles, quantile_estimate, alpha)\n",
        "\n",
        "# ======================\n",
        "# 4. Вывод результатов\n",
        "# ======================\n",
        "print(f\"\\n{' Результаты ':=^60}\")\n",
        "print(f\"• Точечная оценка 90% квантиля: {quantile_estimate:.2f} минут\")\n",
        "print(f\"• Стандартная ошибка (бутстреп): {std_error:.2f}\")\n",
        "print(f\"• Нормальный {confidence_level}% CI: ({normal_ci[0]:.2f}, {normal_ci[1]:.2f})\")\n",
        "print(f\"• Перцентильный {confidence_level}% CI: ({percentile_ci[0]:.2f}, {percentile_ci[1]:.2f})\")\n",
        "print(f\"• Центральный {confidence_level}% CI: ({pivotal_ci[0]:.2f}, {pivotal_ci[1]:.2f})\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ======================\n",
        "# 5. Визуализация\n",
        "# ======================\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.set_style(\"whitegrid\")\n",
        "palette = sns.color_palette(\"husl\", 4)\n",
        "\n",
        "# Общие параметры графиков\n",
        "plot_params = {\n",
        "    'bootstrap': {'color': palette[0], 'label': 'Бутстреп-распределение'},\n",
        "    'estimate': {'color': palette[1], 'label': f'Точечная оценка ({quantile_estimate:.1f})'},\n",
        "    'ci_line': {'color': palette[2], 'linestyle': '--', 'linewidth': 2},\n",
        "    'ci_fill': {'color': palette[2], 'alpha': 0.1}\n",
        "}\n",
        "\n",
        "# 5.1 Нормальный CI\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.kdeplot(bootstrap_quantiles, **plot_params['bootstrap'])\n",
        "plt.axvline(quantile_estimate, color=plot_params['estimate']['color'],\n",
        "            linewidth=2.5, label=plot_params['estimate']['label'])\n",
        "plt.axvline(normal_ci[0], **plot_params['ci_line'], label=f'{confidence_level}% ДИ')\n",
        "plt.axvline(normal_ci[1], **plot_params['ci_line'])\n",
        "plt.axvspan(normal_ci[0], normal_ci[1], **plot_params['ci_fill'])\n",
        "plt.title('Нормальный доверительный интервал', fontsize=12)\n",
        "plt.xlabel('Время доставки (минуты)')\n",
        "plt.ylabel('Плотность')\n",
        "plt.legend()\n",
        "\n",
        "# 5.2 Перцентильный CI\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.kdeplot(bootstrap_quantiles, **plot_params['bootstrap'])\n",
        "plt.axvline(quantile_estimate, color=plot_params['estimate']['color'],\n",
        "            linewidth=2.5, label=plot_params['estimate']['label'])\n",
        "plt.axvline(percentile_ci[0], **plot_params['ci_line'], label=f'{confidence_level}% ДИ')\n",
        "plt.axvline(percentile_ci[1], **plot_params['ci_line'])\n",
        "plt.axvspan(percentile_ci[0], percentile_ci[1], **plot_params['ci_fill'])\n",
        "plt.title('Перцентильный доверительный интервал', fontsize=12)\n",
        "plt.xlabel('Время доставки (минуты)')\n",
        "plt.ylabel('')\n",
        "\n",
        "# 5.3 Центральный CI\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.kdeplot(bootstrap_quantiles, **plot_params['bootstrap'])\n",
        "plt.axvline(quantile_estimate, color=plot_params['estimate']['color'],\n",
        "            linewidth=2.5, label=plot_params['estimate']['label'])\n",
        "plt.axvline(pivotal_ci[0], **plot_params['ci_line'], label=f'{confidence_level}% ДИ')\n",
        "plt.axvline(pivotal_ci[1], **plot_params['ci_line'])\n",
        "plt.axvspan(pivotal_ci[0], pivotal_ci[1], **plot_params['ci_fill'])\n",
        "plt.title('Центральный доверительный интервал', fontsize=12)\n",
        "plt.xlabel('Время доставки (минуты)')\n",
        "plt.ylabel('')\n",
        "\n",
        "plt.suptitle('Сравнение методов построения доверительных интервалов для 90% квантиля времени доставки',\n",
        "             fontsize=14, y=1.05)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d2IvLSrQkmOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Бутстреп t-статистики"
      ],
      "metadata": {
        "id": "dL1uS1m6lRPu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Бутстреп t-статистики** – это модификация бутстрепа, которая стремится улучшить точность доверительных интервалов, особенно когда распределение статистики не является идеально нормальным или когда размер выборки не очень велик. Она использует аналогию с классической t-статистикой, но заменяет неизвестные параметры их бутстреп-оценками.\n",
        "\n",
        "**Для чего используется:** Этот метод применяется для построения доверительных интервалов, и, согласно источникам, он сходится к истинной вероятности покрытия быстрее, чем наивный бутстреп. Это означает, что для достижения той же точности доверительного интервала требуется меньший размер выборки N. Однако его использование требует наличия формулы для стандартной ошибки оцениваемой статистики. Если такой формулы нет, приходится прибегать к методу \"бутстреп в бутстрепе\" (двойной бутстреп) для оценки стандартной ошибки. (о нём дальше)\n",
        "\n",
        "**Алгоритм:**\n",
        "\n",
        "1. Вычислить точечную оценку и её стандартную ошибку: По исходным данным вычислить точечную оценку статистики $\\hat{S}$ и её стандартную ошибку $\\text{se}(\\hat{S})$.\n",
        "\n",
        "2. Генерировать бутстреп-выборки: Повторить $B$ раз:\n",
        "\n",
        "  * Сгенерировать бутстреп-выборку $X^*$.\n",
        "  * Для каждой бутстреп-выборки вычислить статистику $\\hat{S}^*$.\n",
        "  * Вычислить бутстреп-аналог t-статистики:\n",
        "  \n",
        "  Если доступна аналитическая формула для стандартной ошибки $\\text{se}( \\hat{S})$, то для каждой бутстреп-выборки можно вычислить бутстреп-аналог t-статистики:\n",
        "  \n",
        "  $$\n",
        "  t^* = \\frac{\\hat{S}^* - \\hat{S}}{\\text{se}( \\hat{S})}\n",
        "  \\quad \\text{ где } \\text{se}(\\hat{S}) \\text{— это оценка стандартной ошибки статистики, вычисленная по бутстреп-выборке } X^*\n",
        "  $$\n",
        "\n",
        "3. Построить доверительный интервал:\n",
        "\n",
        "  Вместо использования квантилей стандартного нормального распределения (как в нормальном CI), используются эмпирические квантили распределения $t^*._{100 \\times (1-\\alpha)} %$ CI для параметра $S$:\n",
        "  \n",
        "  $$ \\text{CI} = \\left[ \\hat{S} - t^*._{( (1-\\alpha/2) \\cdot B )} \\cdot \\text{se}(\\hat{S}) \\text{ ; } \\hat{S} - t^*._{(\\alpha/2 \\cdot B)} \\cdot \\text{se}(\\hat{S}) \\right] $$\n",
        "\n",
        "**Преимущества и Недостатки:**\n",
        "\n",
        "* **Высокая точность:** Обеспечивает более высокую точность доверительных интервалов по сравнению с наивным бутстрепом, особенно для ненормально распределенных статистик, так как быстрее приближает фактическую вероятность покрытия к заказанной.\n",
        "* **Требует формулу для стандартной ошибки:** Главный недостаток — необходимость аналитической формулы для стандартной ошибки статистики. Если такой формулы нет, метод не применим без использования двойного бутстрепа."
      ],
      "metadata": {
        "id": "ds0xVrHNmdZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bootstrap Confidence Intervals for Mean with Analytical Standard Error\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuration\n",
        "np.random.seed(42)  # For reproducibility\n",
        "n = 1000            # Sample size\n",
        "B = 10000           # Number of bootstrap samples\n",
        "alpha = 0.05        # Significance level\n",
        "confidence_level = int((1 - alpha) * 100)\n",
        "\n",
        "# Distribution parameters\n",
        "true_mean, true_std = 90, 20\n",
        "\n",
        "\n",
        "# Data Generation\n",
        "values = np.random.normal(true_mean, true_std, n)\n",
        "\n",
        "\n",
        "# Point Estimates\n",
        "sample_mean = np.mean(values)\n",
        "std_error_analytical = np.std(values, ddof=1) / np.sqrt(n)\n",
        "\n",
        "\n",
        "# Bootstrap Procedure\n",
        "bootstrap_t_stats = np.empty(B)\n",
        "\n",
        "for i in tqdm(range(B), desc=\"Bootstrapping t-statistics\"):\n",
        "    bootstrap_sample = np.random.choice(values, n, replace=True)\n",
        "    bootstrap_mean = np.mean(bootstrap_sample)\n",
        "    bootstrap_std_error = np.std(bootstrap_sample, ddof=1) / np.sqrt(n)\n",
        "    bootstrap_t_stats[i] = (bootstrap_mean - sample_mean) / bootstrap_std_error\n",
        "\n",
        "# Calculate CI using bootstrap t-statistics\n",
        "t_quantiles = np.quantile(bootstrap_t_stats, [alpha/2, 1-alpha/2])\n",
        "ci_lower = sample_mean - t_quantiles[1] * std_error_analytical\n",
        "ci_upper = sample_mean - t_quantiles[0] * std_error_analytical\n",
        "\n",
        "\n",
        "print(f\"\\n{' Bootstrap Results ':=^50}\")\n",
        "print(f\"• Sample mean estimate: {sample_mean:.2f}\")\n",
        "print(f\"• Analytical standard error: {std_error_analytical:.2f}\")\n",
        "print(f\"• {confidence_level}% Confidence Interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.set_style(\"whitegrid\")\n",
        "palette = sns.color_palette(\"husl\", 3)\n",
        "\n",
        "# Main KDE plot\n",
        "ax = sns.kdeplot(bootstrap_t_stats,\n",
        "                 color=palette[0],\n",
        "                 fill=True,\n",
        "                 alpha=0.3,\n",
        "                 linewidth=2,\n",
        "                 label='Bootstrap t-statistics distribution')\n",
        "\n",
        "# Reference lines\n",
        "plt.axvline(0, color='black', linestyle='-',\n",
        "            linewidth=2, label='Expected null value')\n",
        "\n",
        "plt.axvline(t_quantiles[0], color=palette[2],\n",
        "            linestyle='--', linewidth=2,\n",
        "            label=f'{confidence_level}% CI bounds')\n",
        "\n",
        "plt.axvline(t_quantiles[1], color=palette[2],\n",
        "            linestyle='--', linewidth=2)\n",
        "\n",
        "# Confidence interval fill\n",
        "plt.axvspan(t_quantiles[0], t_quantiles[1],\n",
        "            color=palette[2], alpha=0.1)\n",
        "\n",
        "# Add theoretical normal distribution for comparison\n",
        "x = np.linspace(-4, 4, 200)\n",
        "plt.plot(x, stats.norm.pdf(x), 'k--', alpha=0.5,\n",
        "         label='Theoretical N(0,1)')\n",
        "\n",
        "# Customize plot\n",
        "plt.title('Distribution of Bootstrap t-Statistics\\n'\n",
        "          f'with {confidence_level}% Confidence Interval',\n",
        "          fontsize=14, pad=20)\n",
        "plt.xlabel('t-statistic Value', fontsize=12)\n",
        "plt.ylabel('Density', fontsize=12)\n",
        "plt.legend(fontsize=10, frameon=True, framealpha=1)\n",
        "\n",
        "# Add statistics annotation\n",
        "stats_text = (f\"Sample mean: {sample_mean:.1f}\\n\"\n",
        "              f\"Std Error: {std_error_analytical:.2f}\\n\"\n",
        "              f\"CI: ({ci_lower:.1f}, {ci_upper:.1f})\")\n",
        "\n",
        "plt.annotate(stats_text,\n",
        "             xy=(0.75, 0.75),\n",
        "             xycoords='axes fraction',\n",
        "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JTHQL7SAxONi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Бутстреп в бутстрепе"
      ],
      "metadata": {
        "id": "iu3BvJosDBxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Контекст**\n",
        "\n",
        "Однако, основной **недостаток бутстрепа t-статистики** заключается в том, что для её применения требуется аналитическая формула для стандартной ошибки (Standard Error) оцениваемой статистики. Для некоторых распространенных метрик, таких как среднее значение, эта формула хорошо известна. Но для более сложных или \"диковинных\" показателей, например, для медианы, коэффициента Джини, или показателей качества классификации (например, Precision), такой простой и универсальной теоретической формулы для оценки стандартного отклонения может просто не существовать. В таких случаях, бутстреп t-статистики не может быть напрямую применен.\n",
        "\n",
        "Когда \"мудрость предков\" (то есть, готовые аналитические формулы) не предоставляет нам способа для вычисления стандартной ошибки интересующей статистики, бутстреп в бутстрепе приходит на помощь, позволяя оценить эту стандартную ошибку численно. Это делает его незаменимым, так как он позволяет численно исследовать свойства распределений произвольных статистик.\n",
        "\n",
        "**Алгоритм**\n",
        "\n",
        "Бутстреп в бутстрепе (или двухуровневый бутстреп) включает в себя вложенные циклы генерации подвыборок для расчёта стандартной ошибки:\n",
        "\n",
        "1. Предыдущие шаги бутстрепа t-статистики\n",
        "\n",
        "2. Генерировать бутстреп-выборки: Повторить $B_1$ раз:\n",
        "\n",
        "  * Сгенерировать бутстреп-выборку $X^*$.\n",
        "  * Для каждой внешней бутстреп-выборки вычислить статистику $\\hat{S}^*$.\n",
        "  * Для каждой внешней бутстреп-выборки вычислить стандартную ошибку $\\text{se}^*(\\hat{S}^*)$\n",
        "    * Внутри каждой внешней бустреп выборки $X^*$ сгенерировать внутренних $B_2$ бутстреп-выборок $X^{\\ast\\ast}$.\n",
        "    * Для каждой внутренней бутстреп-выборки вычислить статистику $\\hat{S}^{\\ast\\ast}$.\n",
        "    * Оценить стандартную ошибку:\n",
        "  $$\n",
        "  \\text{se}^*(\\hat{S^*}) = \\sqrt{\\frac{\\sum \\left( S^{\\ast\\ast} - \\bar{S^{\\ast\\ast}} \\right)^2 }{B_{2}-1}}\n",
        "  \\quad \\text{ где } \\bar{X^{\\ast\\ast}} \\text{ - среднее значение вычисленной статистики } \\hat{S}^{\\ast\\ast}\n",
        "  $$\n",
        "  * Для каждой внешней бутстреп-выборки вычислить бутстреп-аналог t-статистики:\n",
        "  \n",
        "  $$\n",
        "  t^* = \\frac{\\hat{S}^* - \\hat{S}}{\\text{se}^*(\\hat{S^*})}\n",
        "  \\quad \\text{ где } \\text{se}^*(\\hat{S^*}) \\text{— это оценка стандартной ошибки статистики, вычисленная по внутренним бутстреп-выборкам } X^{\\ast\\ast}\n",
        "  $$\n",
        "\n",
        "3. Следующие шаги бутстрепа t-статистики"
      ],
      "metadata": {
        "id": "uPv5zbq-DLwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuration\n",
        "np.random.seed(42)  # For reproducibility\n",
        "n = 1000            # Original sample size\n",
        "B1 = 2000           # Number of outer bootstrap samples\n",
        "B2 = 5000           # Number of inner bootstrap samples (for SE estimation)\n",
        "alpha = 0.05        # Significance level\n",
        "confidence_level = int((1 - alpha) * 100)\n",
        "\n",
        "# Data Generation\n",
        "true_mean, true_std = 90, 20\n",
        "values = np.random.normal(true_mean, true_std, n)\n",
        "\n",
        "# Point Estimate\n",
        "def calculate_statistic(data):\n",
        "    return np.median(data)  # Example with median\n",
        "\n",
        "S_hat = calculate_statistic(values)  # Original statistic\n",
        "\n",
        "# Double Bootstrap Procedure\n",
        "\n",
        "t_stats = []  # Bootstrap t-statistics\n",
        "\n",
        "for i in tqdm(range(B1), desc=\"Outer bootstrap\"):\n",
        "\n",
        "    # 1. Generate outer bootstrap sample X*\n",
        "    X_star = np.random.choice(values, size=n, replace=True)\n",
        "\n",
        "    # 2. Compute statistic S* for outer sample\n",
        "    S_star = calculate_statistic(X_star)\n",
        "\n",
        "    # 3. Inner bootstrap for SE estimation\n",
        "    S_double_star = []\n",
        "    for _ in range(B2):\n",
        "        # Generate inner bootstrap sample X** from X*\n",
        "        X_double_star = np.random.choice(X_star, size=n, replace=True)\n",
        "        S_double_star.append(calculate_statistic(X_double_star))\n",
        "\n",
        "    S_double_star = np.array(S_double_star)\n",
        "\n",
        "    # 4. Compute SE according to exact formula\n",
        "    S_double_star_mean = np.mean(S_double_star)\n",
        "    se_star = np.sqrt(np.sum((S_double_star - S_double_star_mean)**2) / (B2 - 1))\n",
        "\n",
        "    # 5. Compute t-statistic if SE > 0\n",
        "    if se_star > 1e-8:  # Avoid division by zero\n",
        "        t_stat = (S_star - S_hat) / se_star\n",
        "        t_stats.append(t_stat)\n",
        "\n",
        "# Filter valid t-statistics\n",
        "t_stats = np.array(t_stats)\n",
        "t_stats = t_stats[~np.isnan(t_stats) & ~np.isinf(t_stats)]\n",
        "\n",
        "# Confidence Interval Calculation\n",
        "t_lower = np.quantile(t_stats, alpha/2)\n",
        "t_upper = np.quantile(t_stats, 1 - alpha/2)\n",
        "\n",
        "ci_lower = S_hat - t_upper * se_hat\n",
        "ci_upper = S_hat - t_lower * se_hat\n",
        "\n",
        "# Results Presentation\n",
        "print(f\"\\n{' Double Bootstrap Results ':=^60}\")\n",
        "print(f\"Original statistic (S_hat): {S_hat:.2f}\")\n",
        "print(f\"Estimated standard error (se_hat): {se_hat:.2f}\")\n",
        "print(f\"{confidence_level}% Confidence Interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "# 7. Visualization\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# 1. Plot bootstrap t-statistics distribution\n",
        "sns.kdeplot(t_stats, color='royalblue', fill=True, alpha=0.3,\n",
        "            label='Bootstrap t-statistics distribution')\n",
        "\n",
        "# 2. Add reference lines\n",
        "plt.axvline(0, color='black', linestyle='-', label='Expected t=0')\n",
        "plt.axvline(t_lower, color='red', linestyle='--',\n",
        "            label=f'{confidence_level}% CI bounds')\n",
        "plt.axvline(t_upper, color='red', linestyle='--')\n",
        "\n",
        "# 3. Add CI region\n",
        "plt.axvspan(t_lower, t_upper, color='red', alpha=0.1)\n",
        "\n",
        "# 4. Add theoretical normal for comparison\n",
        "x = np.linspace(-4, 4, 200)\n",
        "plt.plot(x, stats.norm.pdf(x), 'k--', alpha=0.5,\n",
        "         label='Standard Normal N(0,1)')\n",
        "\n",
        "plt.title('Bootstrap t-statistics Distribution\\n'\n",
        "          f'with {confidence_level}% Confidence Interval',\n",
        "          fontsize=14, pad=20)\n",
        "plt.xlabel('t-statistic value', fontsize=12)\n",
        "plt.ylabel('Density', fontsize=12)\n",
        "plt.legend(fontsize=10, frameon=True)\n",
        "\n",
        "# Add statistics annotation\n",
        "stats_text = (f\"Statistic = {S_hat:.2f}\\n\"\n",
        "              f\"SE = {se_hat:.2f}\\n\"\n",
        "              f\"CI = ({ci_lower:.2f}, {ci_upper:.2f})\")\n",
        "plt.annotate(stats_text, xy=(0.75, 0.75), xycoords='axes fraction',\n",
        "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rWVQEMQKDMKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Парный Бутстреп (Paired Bootstrap)"
      ],
      "metadata": {
        "id": "NGPHA_yo05aD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Парный бутстреп** — это вариант бутстрепа, который применяется в моделях, где наблюдения состоят из пар связанных значений, например, в задачах регрессии, где каждая строка данных включает зависимую переменную $Y_i$ и набор независимых переменных $X_i$. Особенностью парного бутстрепа является то, что при генерации бутстреп-выборок всегда выбираются пары (кортежи) $(Y_i, X_i)$ целиком, сохраняя исходную взаимосвязь между ними.\n",
        "\n",
        "**Для чего используется:** Парный бутстреп особенно полезен, когда нужно построить доверительные интервалы для коэффициентов регрессии или других статистик, зависящих от взаимосвязи между переменными, и при этом не делаются строгие предположения о распределении ошибок или структуре данных (например, о гомоскедастичности). Он позволяет избежать нарушения корреляционной структуры между Y и X, которая может быть нарушена, если $X_i$ фиксируются, а $Y_i$ генерируются отдельно (как в диком бутстрепе).\n",
        "\n",
        "**Алгоритм:**\n",
        "\n",
        "1. Исходные данные:\n",
        "\n",
        "  Имеется $n$ пар наблюдений $(Y_1, X_1), \\ldots, (Y_n, X_n)$, где $Y_i$ — зависимая переменная, а $X_i$ — вектор независимых переменных для $i$-го наблюдения.\n",
        "\n",
        "2. Генерация бутстреп-выборки: Повторить $B$ раз:\n",
        "  * Случайно выбрать $n$ пар $(Y_j, X_j)$ из исходных $n$ пар с возвращением. Таким образом, формируется бутстреп-выборка $\\left[ (Y_1, X_1), \\ldots, (Y_n, X_n) \\right]$. Некоторые исходные пары могут быть выбраны несколько раз, другие — ни разу.\n",
        "\n",
        "  * Вычисление статистики: Для каждой бутстреп-выборки оценить интересующую статистику (например, коэффициенты регрессии $\\hat{\\beta}^*$).\n",
        "\n",
        "3. Построение доверительного интервала: Используя собранные $B$ значений статистики (например, $\\hat{\\beta}^1, \\ldots, \\hat{\\beta}^B$), можно построить перцентильный доверительный интервал, аналогично наивному бутстрепу. Для $100 \\times (1-\\alpha)%$ CI:\n",
        "\n",
        "$$\n",
        "\\text{CI} = \\left[ \\hat{\\beta}^*_{(\\alpha/2 \\cdot B)} \\text{ ; } \\hat{\\beta}^*_{( (1-\\alpha/2) \\cdot B )} \\right]\n",
        "$$\n",
        "\n",
        "\n",
        "**Преимущества и Недостатки:**\n",
        "* **Сохранение структуры данных:** Сохраняет зависимость между $Y$ и $X$ в бутстреп-выборках, что важно для корректной оценки параметров моделей, где такая зависимость является ключевой.\n",
        "\n",
        "* **Простота реализации:** По сравнению с диким бутстрепом, концепция и реализация парного бутстрепа проще, так как не требуется работа с остатками и их масштабированием.\n",
        "* **Предположения:** Несмотря на то, что он более гибок, чем параметрические методы, парный бутстреп все еще не идеален в случаях, например, с гетероскедастичностью, особенно если она зависит от X.\n"
      ],
      "metadata": {
        "id": "lExc3hfhfP7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# Configuration\n",
        "np.random.seed(42)\n",
        "n = 1000\n",
        "true_slope = 2\n",
        "true_intercept = 5\n",
        "noise_std = 2\n",
        "\n",
        "# Data Generation\n",
        "X_orig = np.random.rand(n, 1) * 10\n",
        "Y_orig = true_slope * X_orig + true_intercept + np.random.normal(0, noise_std, (n, 1))\n",
        "data = pd.DataFrame({'X': X_orig.flatten(), 'Y': Y_orig.flatten()})\n",
        "\n",
        "# 3. Point Estimates (Statsmodels)\n",
        "X_sm = sm.add_constant(X_orig)\n",
        "model = sm.OLS(Y_orig, X_sm).fit()\n",
        "beta1_estimate = model.params[1]\n",
        "intercept_estimate = model.params[0]\n",
        "\n",
        "# Bootstrap Setup (using Statsmodels)\n",
        "\n",
        "B = 10000\n",
        "alpha = 0.05\n",
        "bootstrap_beta1 = np.zeros(B)\n",
        "\n",
        "# Bootstrap Sampling\n",
        "\n",
        "for i in tqdm(range(B)):\n",
        "    sample = data.sample(n, replace=True)\n",
        "    X_bs = sm.add_constant(sample[['X']])\n",
        "    model_bs = sm.OLS(sample['Y'], X_bs).fit()\n",
        "    bootstrap_beta1[i] = model_bs.params[1]\n",
        "\n",
        "# Percentile Confidence Interval\n",
        "percentile_ci = np.percentile(bootstrap_beta1, [2.5, 97.5])\n",
        "\n",
        "\n",
        "# Results\n",
        "print(f\"\\n{' Bootstrap Regression Results ':=^50}\")\n",
        "print(f\"True slope: {true_slope:.2f}\")\n",
        "print(f\"Estimated slope: {beta1_estimate:.2f}\")\n",
        "print(f\"Bootstrap Percentile 95% CI: ({percentile_ci[0]:.2f}, {percentile_ci[1]:.2f})\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Visualization\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "\n",
        "# Left Plot: Regression Line with Bootstrap CI\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.scatterplot(x='X', y='Y', data=data, alpha=0.3, label='Наблюдения')\n",
        "\n",
        "x_vals = np.linspace(0, 10, 100)\n",
        "y_pred = intercept_estimate + beta1_estimate * x_vals\n",
        "plt.plot(x_vals, y_pred, 'r-', linewidth=2, label='Линия регрессии')\n",
        "\n",
        "# Bootstrap Percentile CI\n",
        "y_lower = intercept_estimate + percentile_ci[0] * x_vals\n",
        "y_upper = intercept_estimate + percentile_ci[1] * x_vals\n",
        "plt.fill_between(x_vals, y_lower, y_upper, color='green', alpha=0.2,\n",
        "                 label='95% доверительный интервал')\n",
        "\n",
        "plt.title('Линейная регрессия с бутстреп доверительным интервалом', fontsize=14)\n",
        "plt.xlabel('X', fontsize=12)\n",
        "plt.ylabel('Y', fontsize=12)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "# Right Plot: Bootstrap Distribution\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.kdeplot(bootstrap_beta1, fill=True, alpha=0.3,\n",
        "            label='Распределение оценок')\n",
        "\n",
        "plt.axvline(beta1_estimate, color='r', linestyle='-',\n",
        "            label='Точечная оценка')\n",
        "plt.axvline(percentile_ci[0], color='g', linestyle='--',\n",
        "            label='Границы 95% ДИ')\n",
        "plt.axvline(percentile_ci[1], color='g', linestyle='--')\n",
        "\n",
        "plt.title('Распределение бутстреп-оценок коэффициента наклона', fontsize=14)\n",
        "plt.xlabel('Коэффициент наклона (beta1)', fontsize=12)\n",
        "plt.ylabel('Плотность', fontsize=12)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1sHUYctqGG6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Дикий Бутстреп (Wild Bootstrap)"
      ],
      "metadata": {
        "id": "jxH5cMfF7wrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Дикий бутстреп** — это специализированный вариант бутстрепа, разработанный для моделей, где предполагается, что независимые переменные (предикторы) фиксированы, а случайность присутствует только в зависимой переменной через ошибки (например, в некоторых типах регрессии или временных рядах). Он особенно полезен в условиях гетероскедастичности, то есть когда дисперсия ошибок не является постоянной для всех наблюдений.\n",
        "\n",
        "**Для чего используется**: Дикий бутстреп позволяет корректно оценить неопределенность в регрессионных моделях, когда стандартные допущения о гомоскедастичности нарушены. Он фиксирует значения предикторов ($X_i$) и генерирует новые зависимые переменные ($Y^*_i$) путем добавления к предсказанным значениям $\\hat{Y}_i$ масштабированных и случайным образом измененных остатков $\\hat{u}_i$. Это обеспечивает более точные доверительные интервалы и проверки гипотез, чем парный бутстреп в условиях гетероскедастичности.\n",
        "\n",
        "**Алгоритм:**\n",
        "\n",
        "1. Оценить исходную модель:\n",
        "\n",
        "  По исходным данным $(Y_i, X_i)$ оценить регрессионную модель (например, $Y_i = \\beta X_i + u_i$) и получить оценки коэффициентов $\\hat{\\beta}$ и остатки (residuals) $\\hat{u}_i = Y_i - \\hat{Y}_i = Y_i - \\hat{\\beta}X_i$.\n",
        "\n",
        "2. Масштабировать остатки:\n",
        "\n",
        "  Остатки $\\hat{u}_i$ могут иметь разную дисперсию, даже если истинные ошибки $u_i$ гомоскедастичны, особенно в линейной регрессии. Чтобы скорректировать это, остатки масштабируются на диагональные элементы матрицы $H = X(X^T X)^{-1} X^T$:\n",
        "  \n",
        "  $$ \\hat{u}_{i}^\\text{scaled} = \\frac{\\hat{u}_i}{\\sqrt{1 - H{i}}}\n",
        "  \\quad \\text{ где } H_{i} \\text{ — i-й диагональный элемент матрицы H}\n",
        "  $$\n",
        "  \n",
        "  Это делается для того, чтобы масштабированные остатки имели одинаковую дисперсию.\n",
        "3. Генерировать бутстреп-выборку: Повторить $B$ раз:\n",
        "  \n",
        "  * Сгенерировать случайные веса $v_i$ для каждого масштабированного остатка. Эти веса должны иметь нулевое математическое ожидание и единичную дисперсию. Часто используются распределения, такие как:\n",
        "    *  ± 1 с вероятностью 0.5 (распределение Радемахера).\n",
        "    * Стандартное нормальное распределение $N(0,1)$.\n",
        "  \n",
        "  * Создать новую зависимую переменную $\\hat{Y}_i^*$ для каждой бутстреп-выборки, используя предсказанные значения из исходной модели $\\hat{Y}_i$ и масштабированные остатки, умноженные на случайные веса:\n",
        "  \n",
        "  $$\n",
        "  Y_i = \\hat{Y}_i + \\hat{u}_i ^\\text{scaled} \\cdot v_i\n",
        "  $$\n",
        "  \n",
        "  При этом независимые переменные $X_i$ остаются фиксированными для всех бутстреп выборок.\n",
        "\n",
        "4. Оценить модель на бутстреп-выборке:\n",
        "\n",
        "  Оценить регрессионную модель на сгенерированных данных $(\\hat{Y}^*_i, X_i)$ для получения бутстреп-оценок коэффициентов $\\hat{\\beta}^*$.\n",
        "\n",
        "5. Построить доверительный интервал или проверить гипотезу:\n",
        "  \n",
        "  Используя собранные $B$ значений $\\hat{\\beta}^*$, можно построить перцентильный доверительный интервал. Для проверки гипотез о равенстве коэффициентов нулю, можно посмотреть на распределение бутстреп-коэффициентов или F-статистики, полученных в предположении нулевой гипотезы.\n",
        "\n",
        "**Преимущества и Недостатки:**\n",
        "\n",
        "* Устойчивость к гетероскедастичности: Главное преимущество — способность корректно обрабатывать гетероскедастичность, что делает его предпочтительным в боевых условиях, где распределение ненормальное и гетероскедастичность присутствует.\n",
        "\n",
        "* Фиксированные предикторы: Предполагает, что предикторы фиксированы, что подходит для экспериментов или временных рядов.\n",
        "\n",
        "* Сложность реализации: Масштабирование остатков и выбор правильных весов могут быть нетривиальными."
      ],
      "metadata": {
        "id": "9xN7wWKL8LO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuration\n",
        "\n",
        "np.random.seed(42)\n",
        "n = 2000\n",
        "true_slope = 2\n",
        "true_intercept = 5\n",
        "\n",
        "# 2. Data Generation with Heteroskedasticity\n",
        "\n",
        "X_orig = np.random.rand(n, 1) * 10\n",
        "errors = np.random.normal(0, 1, (n, 1))\n",
        "Y_orig = true_slope * X_orig + true_intercept + errors\n",
        "\n",
        "data = pd.DataFrame({'X': X_orig.flatten(), 'Y': Y_orig.flatten()})\n",
        "\n",
        "# 3. Original Model Estimation (Statsmodels)\n",
        "X_sm = sm.add_constant(X_orig)\n",
        "model = sm.OLS(Y_orig, X_sm).fit()\n",
        "beta1_estimate = model.params[1]\n",
        "intercept_estimate = model.params[0]\n",
        "residuals = model.resid\n",
        "\n",
        "# Hat matrix and scaled residuals\n",
        "XTX_inv = np.linalg.inv(X_sm.T @ X_sm)\n",
        "h_ii = np.array([X_sm[i] @ XTX_inv @ X_sm[i].T for i in range(n)])\n",
        "scaled_residuals = residuals / np.sqrt(1 - h_ii)\n",
        "\n",
        "# Wild Bootstrap Setup\n",
        "B = 10000\n",
        "alpha = 0.05\n",
        "bootstrap_beta1 = np.zeros(B)\n",
        "\n",
        "\n",
        "# 5. Wild Bootstrap Procedure\n",
        "for i in tqdm(range(B), desc=\"Wild Bootstrap Progress\"):\n",
        "    # Rademacher weights\n",
        "    v_i = np.random.choice([-1, 1], n)\n",
        "\n",
        "    # Construct bootstrap sample\n",
        "    Y_star = model.predict(X_sm) + scaled_residuals * v_i\n",
        "\n",
        "    # Fit bootstrap model\n",
        "    model_bs = sm.OLS(Y_star, X_sm).fit()\n",
        "    bootstrap_beta1[i] = model_bs.params[1]\n",
        "\n",
        "# Confidence Intervals\n",
        "# Percentile CI\n",
        "percentile_ci = np.percentile(bootstrap_beta1, [2.5, 97.5])\n",
        "\n",
        "# Analytical CI from statsmodels\n",
        "analytical_ci = model.conf_int(alpha=0.05)[1]\n",
        "\n",
        "\n",
        "# Results\n",
        "print(f\"\\n{' Regression Results ':=^50}\")\n",
        "print(f\"True slope: {true_slope:.2f}\")\n",
        "print(f\"Estimated slope: {beta1_estimate:.2f}\")\n",
        "print(f\"Analytical 95% CI: ({analytical_ci[0]:.2f}, {analytical_ci[1]:.2f})\")\n",
        "print(f\"Wild Bootstrap 95% CI: ({percentile_ci[0]:.2f}, {percentile_ci[1]:.2f})\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(16, 6))\n",
        "\n",
        "# Left Plot: Regression Line with CIs\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.scatterplot(x='X', y='Y', data=data, alpha=0.3, label='Наблюдения')\n",
        "\n",
        "x_vals = np.linspace(0, 10, 100)\n",
        "y_pred = intercept_estimate + beta1_estimate * x_vals\n",
        "plt.plot(x_vals, y_pred, 'r-', linewidth=2, label='Линия регрессии')\n",
        "\n",
        "# Bootstrap CI\n",
        "plt.fill_between(x_vals,\n",
        "                 intercept_estimate + percentile_ci[0] * x_vals,\n",
        "                 intercept_estimate + percentile_ci[1] * x_vals,\n",
        "                 color='green', alpha=0.2, label='Бутстреп 95% ДИ')\n",
        "\n",
        "# Analytical CI\n",
        "plt.fill_between(x_vals,\n",
        "                 intercept_estimate + analytical_ci[0] * x_vals,\n",
        "                 intercept_estimate + analytical_ci[1] * x_vals,\n",
        "                 color='blue', alpha=0.1, label='Аналитический 95% ДИ')\n",
        "\n",
        "plt.title('Линейная регрессия с доверительными интервалами\\n(Гетероскедастичность)', fontsize=14)\n",
        "plt.xlabel('X', fontsize=12)\n",
        "plt.ylabel('Y', fontsize=12)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "# Right Plot: Bootstrap Distribution\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.kdeplot(bootstrap_beta1, fill=True, alpha=0.3,\n",
        "            label='Распределение оценок')\n",
        "\n",
        "plt.axvline(beta1_estimate, color='r', linestyle='-',\n",
        "            label='Точечная оценка')\n",
        "plt.axvline(percentile_ci[0], color='g', linestyle='--',\n",
        "            label='Бутстреп 95% ДИ')\n",
        "plt.axvline(percentile_ci[1], color='g', linestyle='--')\n",
        "plt.axvline(analytical_ci[0], color='b', linestyle=':',\n",
        "            label='Аналитический 95% ДИ')\n",
        "plt.axvline(analytical_ci[1], color='b', linestyle=':')\n",
        "\n",
        "plt.title('Распределение бутстреп-оценок коэффициента', fontsize=14)\n",
        "plt.xlabel('Коэффициент наклона (beta1)', fontsize=12)\n",
        "plt.ylabel('Плотность', fontsize=12)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "weAzxvhS7ymZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Пуассоновский Бутстреп (Poisson Bootstrap)"
      ],
      "metadata": {
        "id": "z5V72edZ78ei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Пуассоновский бутстреп** — это специальный вид бутстрепа, разработанный для работы с очень большими объемами данных (Big Data) или с потоковыми данными, когда невозможно загрузить всю выборку в память или многократно сэмплировать её с возвращением. В таких сценариях традиционные методы бутстрепа становятся вычислительно слишком затратными.\n",
        "\n",
        "**Для чего используется:** Ключевая идея пуассоновского бутстрепа заключается в том, что вместо явного создания бутстреп-выборок путем выбора $n$ элементов с возвращением из $n$, мы определяем, сколько раз каждое исходное наблюдение попадет в бутстреп-выборку. Это количество раз для каждого наблюдения $i$ генерируется из распределения Пуассона с параметром $\\lambda=1$.\n",
        "\n",
        "**Алгоритм:**\n",
        "1. Связь с биномиальным распределением:\n",
        "\n",
        "  В стандартном бутстрепе количество раз, которое каждое конкретное наблюдение попадает в бутстреп-выборку размера $n$, следует биномиальному распределению $Bin(n, p=1/n)$. При очень большом $n$, это биномиальное распределение хорошо аппроксимируется распределением Пуассона с параметром $\\lambda = n \\cdot (1/n) = 1$.\n",
        "\n",
        "2. Генерация весов:\n",
        "\n",
        "  Для каждого исходного наблюдения $X_i$ (или пары $(Y_i, X_i)$) генерируется случайное целое число $k_i$ из распределения Пуассона $Poiss(1)$. Это число $k_i$ представляет собой \"вес\" или количество копий $X_i$, которое войдет в текущую бутстреп-выборку.\n",
        "\n",
        "3. Формирование бутстреп-статистики:\n",
        "\n",
        "  Вместо создания новой выборки, статистика вычисляется напрямую, используя взвешенные исходные данные. То есть, если мы хотим оценить сумму, мы суммируем $X_i \\cdot k_i$. Если хотим оценить среднее, то $\\sum (X_i \\cdot k_i) / \\sum k_i$.\n",
        "\n",
        "4. Повторение: Шаги 2 и 3 повторяются $B$ раз, чтобы собрать распределение статистики.\n",
        "\n",
        "5. Построение доверительного интервала:\n",
        "\n",
        "  Аналогично наивному бутстрепу, можно использовать перцентильный метод на собранных бутстреп-значениях статистики.\n",
        "\n",
        "**Преимущества и Недостатки:**\n",
        "* Эффективность для Big Data/потоковых данных: Главное преимущество — возможность работать с данными, которые не помещаются в память, или с потоковыми данными. Винни-Пух с двумя числами в голове может посчитать коэффициент регрессии для миллионов наблюдений.\n",
        "* Отсутствие явного ресэмплинга: Нет необходимости создавать физические копии данных, что экономит память и время.\n",
        "*  Приближение: Это аппроксимация стандартного бутстрепа, и хотя она точна для больших N, для малых выборок может быть менее точной."
      ],
      "metadata": {
        "id": "vDePzPnL7zdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuration\n",
        "\n",
        "rng = np.random.default_rng(42)\n",
        "n_stream     = 500_000\n",
        "true_median  = 30.0\n",
        "noise_scale  = 10.0\n",
        "\n",
        "\n",
        "# Data Generation\n",
        "\n",
        "delivery_times = rng.gamma(shape=2, scale=15, size=n_stream)\n",
        "outliers       = rng.uniform(120, 180, size=int(n_stream * 0.01))\n",
        "delivery_times = np.concatenate([delivery_times, outliers])\n",
        "\n",
        "sample_df = pd.DataFrame({'delivery_time': delivery_times[::1000]})\n",
        "\n",
        "\n",
        "# Statistics\n",
        "def weighted_median(data: np.ndarray, weights: np.ndarray) -> float:\n",
        "    \"\"\"Взвешенная (обобщённая) медиана.\n",
        "       Если все веса нулевые, возбуждается исключение.\n",
        "    \"\"\"\n",
        "    total_w = weights.sum()\n",
        "    if total_w == 0:\n",
        "        raise ValueError(\"all Poisson weights are zero\")\n",
        "\n",
        "    order  = np.argsort(data)\n",
        "    cumsum = np.cumsum(weights[order])\n",
        "    cutoff = 0.5 * total_w\n",
        "    idx    = np.searchsorted(cumsum, cutoff, side=\"left\")\n",
        "    return data[order[idx]]\n",
        "\n",
        "original_median = np.median(delivery_times)\n",
        "\n",
        "# Bootstrap parameters\n",
        "B      = 2000\n",
        "alpha  = 0.05\n",
        "ci_pct = (alpha / 2 * 100, (1 - alpha / 2) * 100)\n",
        "ci_lvl = int((1 - alpha) * 100)\n",
        "\n",
        "bootstrap_medians = np.empty(B)\n",
        "\n",
        "# ---------------------- Poisson bootstrap ----------------------\n",
        "for i in tqdm(range(B), desc=\"Poisson bootstrap\"):\n",
        "    weights = rng.poisson(1, size=delivery_times.size)\n",
        "    while weights.sum() == 0:\n",
        "        weights = rng.poisson(1, size=delivery_times.size)\n",
        "    bootstrap_medians[i] = weighted_median(delivery_times, weights)\n",
        "\n",
        "# Confidence intervals\n",
        "ci_lower, ci_upper = np.percentile(bootstrap_medians, ci_pct)\n",
        "\n",
        "# Results\n",
        "print(f\"\\n{' Результаты ':=^50}\")\n",
        "print(f\"Истинная медиана: {true_median:.1f} мин\")\n",
        "print(f\"Оценка медианы:   {original_median:.1f} мин\")\n",
        "print(f\"Пуассоновский {ci_lvl}% ДИ: ({ci_lower:.1f}, {ci_upper:.1f})\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "\n",
        "# Visualization\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "\n",
        "# Chart 1\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(sample_df, x='delivery_time', bins=50,\n",
        "             kde=True, color='skyblue')\n",
        "plt.axvline(original_median, color='red', linestyle='--',\n",
        "            label=f'Медиана: {original_median:.1f} мин')\n",
        "plt.axvline(true_median, color='green', linestyle=':',\n",
        "            label=f'Истинное значение: {true_median:.1f} мин')\n",
        "plt.title('Распределение времени доставки')\n",
        "plt.xlabel('Время (мин)')\n",
        "plt.xlim(0, 150)\n",
        "plt.legend()\n",
        "\n",
        "# Chart 2\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(bootstrap_medians, kde=True, color='salmon',\n",
        "             stat='density', label='Бутстрап-распределение')\n",
        "plt.axvline(original_median, color='red', linestyle='--')\n",
        "plt.axvline(ci_lower, color='blue', linestyle=':', label=f'{ci_lvl}% ДИ')\n",
        "plt.axvline(ci_upper, color='blue', linestyle=':')\n",
        "plt.title('Пуассоновский бутстрап медианы')\n",
        "plt.xlabel('Медианное время доставки')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M39Ha70c7zkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Заключение\n",
        "\n",
        "Бутстреп является крайне универсальным и мощным методом в статистике, позволяющим исследовать свойства распределений произвольных статистик, строить доверительные интервалы и проверять гипотезы даже для нетривиальных метрик, для которых не существуют аналитических формул. Его способность адаптироваться к различным условиям данных (i.i.d., парные данные, гетероскедастичность, потоковые данные) делает его незаменимым инструментом для аналитиков данных и исследователей. Однако важно помнить о его вычислительной трудоёмкости и необходимости учитывать природу данных при выборе конкретного типа бутстрепа"
      ],
      "metadata": {
        "id": "C6rd9g1HTV8a"
      }
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBbI-EN60bQ-"
      },
      "source": [
        "### Задачка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU0-XZJwyBxN"
      },
      "source": [
        "Начнем с задачки:\n",
        "\n",
        "Представьте себе эксперимент, проведенный в 1910 году Джозефом Райаном, который пытался выявить людей с экстрасенсорными способностями. В этом опыте каждый испытуемый должен был угадать цвет 10 карт подряд. Райан считал, что вероятность случайно угадать 9 или 10 карт из десяти - редкое событие, что является свидетельством экстрасенсорных способностей.\n",
        "\n",
        "Из тысячи испытуемых 12 человек угадали 9 из 10 карт, а двое — все 10 карт. Однако последующие эксперименты не подтвердили их способности.\n",
        "\n",
        "1. **Какова вероятность угадать 9 или 10 карт из десяти ?**\n",
        "2. **Если первый этап выявил целых 14 человек, то почему второй этап не подтвердил их способностей, если вероятность быть выявленым на 1 этапе крайне мала?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtXVt72pzkPW"
      },
      "source": [
        "#### Ответы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArFmyvhuo68e"
      },
      "source": [
        "**1. Какова вероятность угадать 9 или 10 карт из десяти ?**\n",
        "\n",
        "Пусть $X$ обозначает событие прогона эксперимента на 1 человеке.\n",
        "Предположим, что вероятность угадать цвет карты без экстрасенсорных способностей $p = 0.5$. Сам эксперимент можно смоделировать с помощью биномиального распределения ⇒ $X \\sim \\text{Bin}(n=10, p=0.5)$\n",
        "\n",
        "1. Вероятность угадать ровно $k$ карт: $P(X = k) = \\binom{10}{k} (0.5)^{10}$\n",
        "\n",
        "2. Вероятность угадать **не менее 9 карт** = $P(X \\geq 9) = P(X=9) + P(X=10)$\n",
        "\n",
        "3. Посчитаем:\n",
        "\n",
        "  $P(X=9) = \\binom{10}{9} (0.5)^{10} = 10 \\times \\frac{1}{1024} \\approx 0.00977$\n",
        "\n",
        "  $P(X=10) = \\binom{10}{10} (0.5)^{10} = 1 \\times \\frac{1}{1024} \\approx 0.00098$\n",
        "\n",
        " $P(X \\geq 9) \\approx 0.00977 + 0.00098 \\approx 0.01075$\n",
        "\n",
        "  То есть **примерно 1.075%** вероятность случайно угадать 9 или 10 карт из 10.\n",
        "\n",
        "<br></br>\n",
        "\n",
        "**2. Если первый этап выявил целых 14 человек, то почему второй этап не подтвердил их способностей, если вероятность быть выявленым на 1 этапе крайне мала?**\n",
        "\n",
        "В пyнкте 1 мы подсчитали, что вероятность угадать 9 или 10 карт из 10 около 1% для человека. Но когда в эксперименте участвует 1000 человек, то порядка 10 человек должны его пройти просто случайно: $(1 - 0.01075)^{1000} \\approx e^{-1000 \\times 0.01075} \\approx e^{-10.75} \\approx 2.1 \\times 10^{-5}$\n",
        "\n",
        "Т.е., вероятность, что **хотя бы один** из 1000 — «удачливый» случайно, равна $1 - e^{-10.75} \\approx 1 - 2.1 \\times 10^{-5} \\approx 0.99998$\n",
        "\n",
        "Это означает, что очень вероятно, что среди 1000 человек найдутся те, кто угадает 9 или более карт случайно. Поэтому обнаружение таких «удачников» — это скорее статистическая иллюзия, а не доказательство экстрасенсорных способностей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDNN4C1Hz-RS"
      },
      "source": [
        "### Фундаментальная проблема множественного тестирования"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZnsKQlj03kL"
      },
      "source": [
        "Именно это явление называется **проблемой множественных сравнений, или проблемой множественного тестирования (multiple testing problem)**.\n",
        "\n",
        "При проведении статистических тестов мы обычно устанавливаем уровень значимости (alpha, $\\alpha$), который определяет максимально допустимую вероятность **ошибки первого рода (Type I error)**. Ошибка первого рода — это ложное отклонение нулевой гипотезы, когда она на самом деле верна. Например, если $\\alpha = 0.05$, это означает, что в 5% случаев мы можем ошибочно заявить о наличии эффекта, когда его нет.\n",
        "\n",
        "Однако, когда мы проводим **несколько статистических тестов одновременно** на одном и том же наборе данных или в рамках одного исследования, вероятность совершить хотя бы одну ошибку первого рода **резко возрастает**. Это и есть суть проблемы множественного тестирования, также известной как проблема множественных сравнений или мультиплицитности.\n",
        "\n",
        "Представьте, что мы проводим 100 тестов, и для каждого из них вероятность ошибки первого рода составляет 5%. Если все нулевые гипотезы на самом деле верны, то **ожидаемое число ложных отклонений составит 5**. Более того, **вероятность получить хотя бы один ложноположительный результат будет близка к 99.4%**, если тесты независимы. Это означает, что почти гарантированно найдется какой-то \"значимый\" результат просто по воле случая. Этот эффект схож с аналогией про обезьян, бесконечно долго стучащих по клавишам, где вероятность того, что хотя бы одна обезьяна напечатает \"Войну и мир\" значительно возрастает с увеличением числа обезьян.\n",
        "\n",
        "___\n",
        "Давайте рассмотрим конкретный пример, смоделировав A/B/n-тест:\n",
        "\n",
        "Предположим, что мы являемся аналитиками в крупной IT-компании и хотим протестировать 50 новых фич в мобильном приложении одновременно (50 параллельных гипотез).  Для каждой фичи мы проводим A/A-тест, т.е. мы знаем, что на самом деле **эффекта нет** для всех 50 фич (все 50 нулевых гипотез верны). Мы хотим оценить, как часто мы будем получать ложноположительные результаты без какой-либо корректировки.\n",
        "\n",
        "Мы будем использовать t-тест для сравнения средних двух групп (контрольной и тестовой) для каждой из 50 фич. Уровень значимости $\\alpha = 0.05$. Для эмпирической оценки мы проведем 100000 симуляций этого сценария.\n",
        "\n",
        "В ходе симуляции мы рассчитаем две ключевые метрики:\n",
        "\n",
        "*   **FWER (Family-Wise Error Rate) – Групповая вероятность ошибки первого рода**: Вероятность того, что **хотя бы один из тестов** даст ложноположительный результат, когда все нулевые гипотезы верны.\n",
        "*   **FDR (False Discovery Rate) – Средняя доля ложных открытий**: Ожидаемая пропорция ложных \"открытий\" (отклоненных нулевых гипотез) среди всех сделанных \"открытий\" (отклонений нулевых гипотез)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fY53dN_K1Mh5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "np.random.seed(42) # Для воспроизводимости результатов\n",
        "\n",
        "# Параметры симуляции\n",
        "num_hypotheses = 50     # Количество параллельных гипотез (фич)\n",
        "alpha_level = 0.05      # Уровень значимости для каждого отдельного теста\n",
        "num_simulations = 3000 # Количество итераций симуляции для эмпирической оценки\n",
        "group_size = 200        # Размер каждой группы (контрольной и тестовой)\n",
        "mu = 0                  # Среднее значение для генерации данных (нет эффекта)\n",
        "std = 1                 # Стандартное отклонение для генерации данных\n",
        "\n",
        "\n",
        "# Инициализация списков для сбора результатов симуляций\n",
        "fwer_results = []\n",
        "fdr_values_per_sim = [] # Для сбора значений V/R в каждой симуляции\n",
        "all_pvalues = [] # Для гистограммы p-value\n",
        "\n",
        "for _ in tqdm(range(num_simulations)):\n",
        "    false_positives_V = 0\n",
        "    total_rejections_R = 0\n",
        "    p_values_batch = []\n",
        "\n",
        "    # Проведение num_hypotheses независимых A/A тестов\n",
        "    for _ in range(num_hypotheses):\n",
        "        control_group = np.random.normal(mu, std, group_size)\n",
        "        treatment_group = np.random.normal(mu, std, group_size)\n",
        "\n",
        "        # Проведение t-теста для сравнения средних\n",
        "        pvalue = stats.ttest_ind(control_group, treatment_group).pvalue\n",
        "        p_values_batch.append(pvalue)\n",
        "\n",
        "        # Определение, является ли тест значимым (ложным открытием, т.к. все H0 верны)\n",
        "        if pvalue < alpha_level:\n",
        "            false_positives_V += 1\n",
        "            total_rejections_R += 1 # В A/A тесте все 'rejections' - это 'false positives'\n",
        "\n",
        "    all_pvalues.extend(p_values_batch)\n",
        "\n",
        "    # Эмпирическая оценка FWER: хотя бы одно ложное открытие\n",
        "    if false_positives_V >= 1:\n",
        "        fwer_results.append(1)\n",
        "    else:\n",
        "        fwer_results.append(0)\n",
        "\n",
        "    # Эмпирическая оценка FDR: V/R. Если R=0, V/R=0.\n",
        "    if total_rejections_R > 0:\n",
        "        fdr_values_per_sim.append(false_positives_V / total_rejections_R)\n",
        "    else:\n",
        "        fdr_values_per_sim.append(0)\n",
        "\n",
        "# Вычисление эмпирических значений FWER и FDR\n",
        "empirical_fwer = np.mean(fwer_results)\n",
        "empirical_fdr = np.mean(fdr_values_per_sim)\n",
        "\n",
        "print(f\"\\nЭмпирическая вероятность >=1 ложного обнаружения (FWER) для {num_hypotheses} гипотез при alpha={alpha_level}: {empirical_fwer:.4f}\")\n",
        "print(f\"Эмпирическая ожидаемая доля ложных открытий (FDR) для {num_hypotheses} гипотез при alpha={alpha_level}: {empirical_fdr:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O03f0OHK8YEL"
      },
      "source": [
        "### Формальное обоснование"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkXs1SPf8L9j"
      },
      "source": [
        "Предположим, у нас есть $m$ проверяемых нулевых гипотез: $H_1, H_2, \\ldots, H_m$.\n",
        "Результаты этих тестов можно классифицировать следующим образом:\n",
        "\n",
        "|                   | Нулевая гипотеза верна ($H_0$) | Альтернативная гипотеза верна ($H_A$) | Всего                  |\n",
        "| :---------------- | :----------------------------- | :---------------------------------- | :--------------------- |\n",
        "| **Отклоняем $H_0$** | $V$ (Ложноположительные)         | $S$ (Истинноположительные)        | $R = V + S$ (Все отклоненные) |\n",
        "| **Не отклоняем $H_0$** | $U$ (Истинноотрицательные)     | $T$ (Ложноотрицательные)          | $m - R$                |\n",
        "| **Всего**         | $m_0$ (Истинные $H_0$)           | $m - m_0$ (Истинные $H_A$)          | $m$ (Общее число гипотез) |\n",
        "\n",
        "Здесь:\n",
        "*   $m$: Общее количество тестируемых гипотез.\n",
        "*   $m_0$: Неизвестное количество истинных нулевых гипотез.\n",
        "*   $V$: Количество **ложно положительных результатов (ошибок первого рода)**, также называемых \"ложными открытиями\".\n",
        "*   $S$: Количество **истинно положительных результатов**, или \"истинных открытий\".\n",
        "*   $R = V + S$: Общее количество **отклоненных нулевых гипотез**, или \"открытий\".\n",
        "*   $T$: Количество **ложно отрицательных результатов (ошибок второго рода)**.\n",
        "*   $U$: Количество **истинно отрицательных результатов**.\n",
        "\n",
        "<br></br>\n",
        "\n",
        "**FWER (Family-Wise Error Rate)**\n",
        "\n",
        "**FWER** — это вероятность того, что **хотя бы одна** из истинных нулевых гипотез будет ошибочно отклонена. Формально:\n",
        "$$ \\text{FWER} = P(V \\geq 1) $$\n",
        "\n",
        "Предположим, что все $m$ гипотез являются истинными нулевыми гипотезами ($m_0 = m$), и все тесты статистически **независимы** друг от друга.\n",
        "Вероятность не совершить ошибку первого рода в одном тесте равна $1 - \\alpha$.\n",
        "Если тесты независимы, вероятность не совершить ни одной ошибки первого рода среди $m$ тестов (то есть $V=0$) равна произведению вероятностей не ошибиться в каждом тесте:\n",
        "$$ P(V=0) = (1-\\alpha)^m $$\n",
        "Следовательно, вероятность совершить хотя бы одну ошибку первого рода (FWER) равна:\n",
        "$$ \\text{FWER} = 1 - P(V=0) = \\mathbf{1 - (1-\\alpha)^m} $$\n",
        "\n",
        "Для **малых значений $\\alpha$** (что обычно и бывает) эта формула может быть аппроксимирована:\n",
        "Используя разложение Тейлора $ (1-x)^n \\approx 1 - nx $ для малых $x$:\n",
        "$$ 1 - (1-\\alpha)^m \\approx 1 - (1 - m\\alpha) = \\mathbf{m\\alpha} $$\n",
        "\n",
        "Это наиболее строгий критерий, стремящийся минимизировать шанс на любую ошибку первого рода в целом семействе тестов.\n",
        "\n",
        "<br></br>\n",
        "\n",
        "**FDR (False Discovery Rate)**\n",
        "\n",
        "**FDR** — это ожидаемая доля ложных открытий среди всех сделанных открытий (отклоненных гипотез). Формально:\n",
        "$$ \\text{FDR} = E\\left[\\frac{V}{R}\\right] $$\n",
        "Чтобы избежать деления на ноль, если $R=0$, доля $V/R$ определяется как 0. Таким образом, более точная запись:\n",
        "$$ \\text{FDR} = E\\left[\\frac{V}{\\max(R,1)}\\right] $$\n",
        "FWER контролирует вероятность хотя бы одного ложного открытия, в то время как FDR контролирует ожидаемую *пропорцию* ложных открытий. Это делает FDR менее строгим, но более мощным подходом, который часто используется в разведочных исследованиях, где допустима некоторая доля ложных открытий, при условии, что общее количество истинных открытий значительно выше.\n",
        "\n",
        "В случае, когда **все $m$ нулевых гипотез истинны** ($m_0 = m$), любое отклонение нулевой гипотезы будет ложным открытием. Следовательно, $V = R$ для всех случаев, когда $R > 0$.\n",
        "Если $R = 0$, то $V = 0$, и $V/R$ по определению равно 0.\n",
        "Таким образом, $V/R$ будет равно 1, если есть хотя бы одно отклонение ($R > 0$), и 0, если отклонений нет ($R = 0$).\n",
        "$$ \\frac{V}{\\max(R,1)} = \\begin{cases} 1 & \\text{если } R > 0 \\\\ 0 & \\text{если } R = 0 \\end{cases} $$\n",
        "Математическое ожидание этой величины:\n",
        "$$ \\text{FDR} = E\\left[\\frac{V}{\\max(R,1)}\\right] = 1 \\cdot P(R > 0) + 0 \\cdot P(R = 0) = P(R > 0) $$\n",
        "Поскольку в случае полной нулевой гипотезы $V = R$, то $P(R > 0) = P(V \\geq 1)$.\n",
        "Мы уже определили $P(V \\geq 1)$ как FWER.\n",
        "Следовательно, **при условии, что все нулевые гипотезы истинны и тесты независимы:**\n",
        "$$ \\mathbf{\\text{FDR} = \\text{FWER} = 1 - (1-\\alpha)^m} $$\n",
        "\n",
        "<br></br>\n",
        "\n",
        "Давайте визуализируем, как FWER и FDR меняются в зависимости от количества тестируемых гипотез. Для этого мы проведем симуляции для разного числа гипотез."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpgH-4J28ndK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "np.random.seed(42) # Для воспроизводимости результатов\n",
        "\n",
        "# Параметры симуляции\n",
        "hypotheses_range = range(50)\n",
        "alpha_level = 0.05      # Уровень значимости для каждого отдельного теста\n",
        "num_simulations = 1000 # Количество итераций симуляции для эмпирической оценки\n",
        "group_size = 200        # Размер каждой группы (контрольной и тестовой)\n",
        "mu = 0                  # Среднее значение для генерации данных (нет эффекта)\n",
        "std = 1\n",
        "\n",
        "\n",
        "fwer_empirical_over_m = []\n",
        "fdr_empirical_over_m = []\n",
        "fwer_theoretical_over_m = []\n",
        "fdr_theoretical_complete_null_over_m = [] # FDR = FWER under complete null\n",
        "\n",
        "for m in tqdm(hypotheses_range, desc=\"Simulating for different m\"):\n",
        "    fwer_results_m = []\n",
        "    fdr_values_per_sim_m = []\n",
        "\n",
        "    for _ in range(num_simulations):\n",
        "        false_positives_V = 0\n",
        "        total_rejections_R = 0\n",
        "\n",
        "        for _ in range(m):\n",
        "            control_group = np.random.normal(mu, std, group_size)\n",
        "            treatment_group = np.random.normal(mu, std, group_size)\n",
        "            pvalue = stats.ttest_ind(control_group, treatment_group).pvalue\n",
        "\n",
        "            if pvalue < alpha_level:\n",
        "                false_positives_V += 1\n",
        "                total_rejections_R += 1\n",
        "\n",
        "        if false_positives_V >= 1:\n",
        "            fwer_results_m.append(1)\n",
        "        else:\n",
        "            fwer_results_m.append(0)\n",
        "\n",
        "        if total_rejections_R > 0:\n",
        "            fdr_values_per_sim_m.append(false_positives_V / total_rejections_R)\n",
        "        else:\n",
        "            fdr_values_per_sim_m.append(0)\n",
        "\n",
        "    fwer_empirical_over_m.append(np.mean(fwer_results_m))\n",
        "    fdr_empirical_over_m.append(np.mean(fdr_values_per_sim_m))\n",
        "    fwer_theoretical_over_m.append(1 - (1 - alpha_level)**m)\n",
        "    fdr_theoretical_complete_null_over_m.append(1 - (1 - alpha_level)**m)\n",
        "\n",
        "# Визуализация роста FWER и FDR\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(hypotheses_range, fwer_empirical_over_m, marker='o', label='Эмпирический FWER')\n",
        "plt.plot(hypotheses_range, fwer_theoretical_over_m, linestyle='--', color='red', label='Теоретический FWER ($1 - (1-\\\\alpha)^m$)')\n",
        "plt.axhline(alpha_level, color='gray', linestyle=':', label=f'Alpha ({alpha_level})')\n",
        "plt.title('Рост FWER с количеством гипотез')\n",
        "plt.xlabel('Количество гипотез (m)')\n",
        "plt.ylabel('FWER')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(hypotheses_range, fdr_empirical_over_m, marker='o', label='Эмпирический FDR')\n",
        "plt.plot(hypotheses_range, fdr_theoretical_complete_null_over_m, linestyle='--', color='red', label='Теоретический FDR (полная нулевая гипотеза)')\n",
        "plt.axhline(alpha_level, color='gray', linestyle=':', label=f'Alpha ({alpha_level})')\n",
        "plt.title('Рост FDR с количеством гипотез (полная нулевая гипотеза)')\n",
        "plt.xlabel('Количество гипотез (m)')\n",
        "plt.ylabel('FDR')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuNlSBnTetoD"
      },
      "source": [
        "### Критические последствия"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdBNl4QiEaZ4"
      },
      "source": [
        "Некорректный учет множественного тестирования имеет серьезные последствия в различных областях:\n",
        "\n",
        "*   **FWER: Ложные лекарственные назначения в медицине**\n",
        "    В медицинских исследованиях, где безопасность пациентов является наивысшим приоритетом, контроль **FWER** критически важен. Представьте, если при тестировании нового лекарства на множество побочных эффектов или при сравнении нескольких вариантов лечения, мы ошибочно идентифицируем \"положительный\" эффект там, где его нет, или, что еще хуже, заявляем об отсутствии побочного эффекта, когда он существует. **Одно ложное обнаружение (FWER)** может привести к одобрению неэффективного или опасного препарата, ложным назначениям и, как следствие, **вреду для здоровья и жизни пациентов**. Медицинские исследования, как правило, стремятся к очень низкому FWER, чтобы свести к минимуму риск таких катастрофических ошибок.\n",
        "\n",
        "*   **FDR: Некорректные рекомендации в E-commerce**\n",
        "    В сфере электронной коммерции или персонализированных рекомендаций, где число тестируемых гипотез (например, различные дизайны кнопок, варианты рекомендаций, рекламные креативы) может достигать сотен и тысяч, строгий контроль FWER часто оказывается слишком консервативным и приводит к потере мощности. Здесь чаще предпочитают контролировать **FDR**. Однако, если FDR не контролируется должным образом, это может привести к **десяткам или сотням ложноположительных \"побед\"**. Например, команда может внедрить \"новый алгоритм рекомендаций\", который на самом деле не приносит пользы, или \"оптимизированную кнопку\", которая не улучшает конверсию, но была признана значимой чисто случайно. Это приводит к **неэффективному расходованию ресурсов**, замедлению роста продукта и, в конечном итоге, к потере доверия к data-driven подходу.\n",
        "\n",
        "*   **P-hacking и проблема невоспроизводимости научных исследований**\n",
        "    Практика проведения множества сравнений без соответствующей корректировки, часто с целью найти хоть что-то \"значимое\", известна как **\"p-hacking\"**. Это приводит к появлению большого количества **\"фейковых корреляций\"** (spurious correlations), которые не имеют под собой реальной основы и возникают просто из-за огромного количества возможных сравнений в больших наборах данных.\n",
        "    Последствия такой практики особенно ярко проявляются в проблеме **невоспроизводимости научных исследований**. Например, масштабный проект **Open Science Collaboration (2015)**, пытавшийся воспроизвести результаты 100 психологических экспериментов, показал, что лишь около 36% из них смогли быть успешно воспроизведены. Одной из ключевых причин такой низкой воспроизводимости, помимо других факторов, считается недостаточное или некорректное применение поправок на множественное тестирование в оригинальных исследованиях. Результаты, которые изначально казались статистически значимыми, оказывались случайными выбросами при повторных, независимых проверках.\n",
        "\n",
        "В заключение, проблема множественного тестирования является фундаментальным вызовом в статистике, требующим строгого подхода. Для ее решения были разработаны различные корректирующие процедуры, такие как поправка Бонферрони, метод Холма, метод Бенджамини-Хохберга и метод Бенджамини-Йекутиели, каждая из которых имеет свои преимущества и ограничения в зависимости от требуемого уровня контроля ошибок и типа данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMV63YfHe5m7"
      },
      "source": [
        "### Методы контроля ошибок"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1a9UtpDiI9w"
      },
      "source": [
        "#### FWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11DHqzi4iLmx"
      },
      "source": [
        "##### Поправка Бонферрони"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXAIwRKmiWl_"
      },
      "source": [
        "**Формулировка**\n",
        "\n",
        "Метод Бонферрони предлагает использовать для проверки каждой гипотезы уровень значимости, равный $\\alpha/m$, где $m$ — количество гипотез. Гипотеза отвергается, если ее $p$-value $p_i \\le \\alpha/m$.\n",
        "\n",
        "**Доказательство**\n",
        "\n",
        "Данная поправка позволяет гарантировать, что $FWER \\le \\alpha$. Это следует из неравенства Буля: для конечного набора событий вероятность того, что произойдет хотя бы одно, не больше, чем сумма вероятностей индивидуальных событий.\n",
        "\n",
        "  Таким образом, если каждый индивидуальный тест проверяется на уровне значимости $\\alpha/m$, то для всего семейства гипотез уровень значимости фиксируется на уровне $\\alpha$:\n",
        "\n",
        "$$\n",
        "FWER = P(V \\ge 1) = P\\left\\{\\bigcup _{i=1}^{m}\\left(p_{i}\\leq {\\frac {\\alpha }{m}}\\right)\\right\\}\\leq \\sum _{i=1}^{m}P\\left(p_{i}\\leq {\\frac {\\alpha }{m}}\\right)\\leq m{\\frac {\\alpha }{m}}=\\alpha\n",
        "$$\n",
        "\n",
        "**Замечание**\n",
        "\n",
        "Метод Бонферрони является наиболее консервативным и его основной минус в том, что он сильно снижает мощность критерия с увеличением числа гипотез, увеличивая вероятность принятия неверной гипотезы (ошибка II рода). Этот метод прост в реализации, но уступает в мощности другим поправкам."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TH7-ScUrMGmn"
      },
      "outputs": [],
      "source": [
        "def apply_bonferroni_correction(pvalues: np.ndarray, alpha: float = 0.05) -> np.ndarray:\n",
        "    \"\"\"ручная реализация поправки Бонферрони\"\"\"\n",
        "    return pvalues < alpha / len(pvalues)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maH8Jft3iW4u"
      },
      "source": [
        "##### Метод Холма (поправка Холма — Бонферрони)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTkOxY-QiW7Z"
      },
      "source": [
        "**Алгоритм**\n",
        "\n",
        "Последовательно перебираем значения p-value из ряда $p_{(1)}, p_{(2)}, \\dots, p_{(m)}$. Если $p_{(i)} < \\alpha / (m - i + 1)$, то отклоняем $H_{(i)}$ и переходим к следующему значению. Иначе говорим, что данные гипотезам $H_{(i)}, \\dots, H_{(m)}$ не противоречат.\n",
        "\n",
        "  1.  **Упорядочить $p$-значения**: Отсортировать $p$-значения по возрастанию: $p_{(1)} \\le p_{(2)} \\le ... \\le p_{(m)}$.\n",
        "  2.  **Последовательная проверка**:\n",
        "      *   Для $i=1$: Если $p_{(1)} \\ge \\alpha/(m-1+1)$, принять гипотезы $H_{(1)}, ..., H_{(m)}$ и остановиться. Иначе, если $p_{(1)} < \\alpha/(m-1+1)$, отвергнуть гипотезу $H_{(1)}$ и продолжить проверку оставшихся гипотез на уровне значимости $\\alpha/(m-2+1)$.\n",
        "      *   Для $i=2$: Если $p_{(2)} \\ge \\alpha/(m-2+1)$, принять гипотезы $H_{(2)}, ..., H_{(m)}$ и остановиться. Иначе, если $p_{(2)} < \\alpha/(m-2+1)$, отвергнуть гипотезу $H_{(2)}$ и продолжить проверку оставшихся гипотез на уровне значимости $\\alpha/(m-3+1)$.\n",
        "      *   И так далее, пока условие не будет нарушено. Точка останова алгоритма — момент $i$, когда принята первая основная гипотеза $H_{(i)}$, при этом принимаются и все последующие $H_{(j)}$ для $j > i$.\n",
        "      \n",
        "\n",
        "\n",
        "**Замечание**\n",
        "\n",
        "Процедура Холма обеспечивает $FWER \\le \\alpha$. Она \"равномерно мощнее\" метода Бонферрони, что означает, что при любом числе экспериментов значение групповой вероятности ошибки II рода при использовании метода Холма не выше, чем при использовании поправки Бонферрони.\n",
        "\n",
        "Более того, без дополнительных предположений нельзя построить процедуру более мощную, чем метод Холма"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1hrN7LeY-XR"
      },
      "outputs": [],
      "source": [
        "def apply_holm_correction(pvalues: np.ndarray, alpha: float = 0.05) -> np.ndarray:\n",
        "    \"\"\"Ручная реализация поправки Холма-Бонферрони.\"\"\"\n",
        "    n = len(pvalues)\n",
        "    sorted_indices = np.argsort(pvalues)\n",
        "    sorted_pvalues = pvalues[sorted_indices]\n",
        "\n",
        "    rejected = np.zeros(n, dtype=bool)\n",
        "    for i, (p, idx) in enumerate(zip(sorted_pvalues, sorted_indices)):\n",
        "        if p < alpha / (n - i):\n",
        "            rejected[idx] = True\n",
        "        else:\n",
        "            break  #процедура остановки при первом непринятии\n",
        "\n",
        "    return rejected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBUj4x0Gs-UQ"
      },
      "source": [
        "##### Медок Шидака"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb1Ndt5_s-c3"
      },
      "source": [
        "**Формулировка**\n",
        "\n",
        "Уровень значимости для $m$ гипотез задается следующим образом: $\\alpha_m = 1 - (1-\\alpha)^{1/m}$. Гипотеза отвергается, если $p_i \\le \\alpha_m$.\n",
        "\n",
        "**Обоснование**\n",
        "\n",
        "Метод Шидака дает $FWER \\le \\alpha$ при условии, что статистики независимы или выполнено свойство \"положительной зависимости\". Если тесты независимы, вероятность отсутствия ошибок I рода для всех $m$ тестов составляет $(1-\\alpha^*)^m$, где $\\alpha^*$ — уровень значимости для одного теста. Чтобы $FWER = \\alpha$, необходимо $1 - (1-\\alpha^*)^m = \\alpha$, откуда $\\alpha^* = 1 - (1-\\alpha)^{1/m}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73xPmV9EttlV"
      },
      "outputs": [],
      "source": [
        "def apply_sidak_correction(pvalues: np.ndarray, alpha: float = 0.05) -> np.ndarray:\n",
        "    \"\"\"Ручная реализация поправки Шидака.\"\"\"\n",
        "    n = len(pvalues)\n",
        "    sidak_alpha = 1 - (1 - alpha) ** (1/n)\n",
        "    return pvalues < sidak_alpha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lg1gJCxiMNW"
      },
      "source": [
        "#### FDR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkrlUbimiMi-"
      },
      "source": [
        "##### Процедура Бенджамини-Хохберга"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4vNwSIhtva4"
      },
      "source": [
        "**Алгоритм**\n",
        "\n",
        "  1. Упорядочить $p$-value: Для заданного $\\alpha$, упорядочить $p$-value по возрастанию: $p_{(1)} \\le p_{(2)} \\le ... \\le p_{(m)}$.\n",
        "  2. Найти максимальное $k$: Найти наибольшее $k$ такое, что $p_{(k)} \\le \\frac{k}{m}\\alpha$.\n",
        "  3. Отклонить гипотезы: Отклонить нулевые гипотезы для всех $H_{(i)}$ для $i = 1, \\dots, k$.\n",
        "  \n",
        "  Геометрически это соответствует построению графика $p_{(k)}$ против $k$ (по осям $y$ и $x$ соответственно), проведению линии через начало координат с наклоном $\\alpha/m$, и объявлению открытий для всех точек слева, до и включая последнюю точку, которая не находится выше линии\n",
        "  .\n",
        "\n",
        "\n",
        "\n",
        "Процедура BH была доказана для контроля FDR для независимых тестов в 1995 году Бенджамини и Хохбергом -> этот метод контролирует FDR на уровне $\\alpha$, если статистики **независимы**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpcSHGS6tvtd"
      },
      "outputs": [],
      "source": [
        "def apply_bh_correction(pvalues: np.ndarray, alpha: float = 0.05) -> np.ndarray:\n",
        "    \"\"\"Ручная реализация метода Бенджамини-Хохберга (FDR)\"\"\"\n",
        "    n = len(pvalues)\n",
        "    sorted_indices = np.argsort(pvalues)\n",
        "    sorted_pvalues = pvalues[sorted_indices]\n",
        "\n",
        "    # Вычисляем критические значения\n",
        "    critical_values = (np.arange(n) + 1) * alpha / n\n",
        "\n",
        "    # Находим наибольшее значимое p-value\n",
        "    max_significant_idx = np.where(sorted_pvalues <= critical_values)[0]\n",
        "    rejected = np.zeros(n, dtype=bool)\n",
        "    if len(max_significant_idx) > 0:\n",
        "        rejected[sorted_indices[:max_significant_idx[-1]+1]] = True\n",
        "\n",
        "    return rejected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfQkJ58-twOg"
      },
      "source": [
        "##### Метод Бенджамини-Екутиели (BY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0My2gRx5twSY"
      },
      "source": [
        "**Формулировка**\n",
        "\n",
        "Процедура Бенджамини-Екутиели (Benjamini–Yekutieli, BY) контролирует долю ложных открытий при произвольных зависимостях между тестовыми статистиками. Она модифицирует порог и находит наибольшее $k$ такое, что: $P_{(k)} \\le \\frac{k}{m \\cdot c(m)}\\alpha$\n",
        "\n",
        "  * Если тесты независимы или положительно коррелированы (как в процедуре Бенджамини-Хохберга): $c(m) = 1$.\n",
        "  \n",
        "  * При произвольной зависимости (включая случай отрицательной корреляции), $c(m)$ — это гармоническое число: $c(m) = \\sum_{i=1}^{m} \\frac{1}{i}$. Это можно аппроксимировать с использованием разложения в ряд Тейлора и константы Эйлера-Маскерони ($\\gamma = 0.57721...$): $\\sum_{i=1}^{m} \\frac{1}{i} \\approx \\ln(m) + \\gamma + \\frac{1}{2m}$.\n",
        "\n",
        "\n",
        "BY-процедура специально разработана для обеспечения контроля FDR в условиях произвольной зависимости между тестовыми статистиками, что делает ее более универсальной по сравнению с BH, которая гарантирует контроль FDR только при независимости или положительной зависимости"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkxoemTltwgi"
      },
      "outputs": [],
      "source": [
        "def apply_by_correction(pvalues: np.ndarray, alpha: float = 0.05) -> np.ndarray:\n",
        "    \"\"\"Ручная реализация метода Бенджамини-Екутиели (BY)\"\"\"\n",
        "    n = len(pvalues)\n",
        "    c_n = np.sum(1 / np.arange(1, n+1))  # Гармонический ряд\n",
        "\n",
        "    sorted_indices = np.argsort(pvalues)\n",
        "    sorted_pvalues = pvalues[sorted_indices]\n",
        "\n",
        "    # Вычисляем критические значения BY\n",
        "    critical_values = (np.arange(n) + 1) * alpha / (n * c_n)\n",
        "\n",
        "    # Находим наибольшее значимое p-value\n",
        "    max_significant_idx = np.where(sorted_pvalues <= critical_values)[0]\n",
        "    rejected = np.zeros(n, dtype=bool)\n",
        "    if len(max_significant_idx) > 0:\n",
        "        rejected[sorted_indices[:max_significant_idx[-1]+1]] = True\n",
        "\n",
        "    return rejected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQLkPXCoa9bS"
      },
      "source": [
        "#### Что в итоге использовать-то?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir31gZaEa9e6"
      },
      "source": [
        "\n",
        "Для начала разберемся с метрикой: как выбрать между FWER, FDR или еще чем-то?\n",
        "\n",
        "Как часто бывает, правильного ответа тут нет. Все зависит от конкретного кейса.\n",
        "\n",
        "* Если имеется множество гипотез, из которых **хочется выбрать наиболее \"интересные\"** для дальнейшего анализа, можно опираться на **FDR**: так мы будем пропускать меньше реальных эффектов, а строгость в отношении ошибки I рода не так важна\n",
        "\n",
        "* Если гипотез немного и тестируется фича, которая потенциально **сильно может сказаться на ключевых метриках** (например, на деньгах) как отрицательно (в особенности), так и положительно – надежней использовать **FWER** в силу его бОльшей консервативности в отношении ошибки I рода\n",
        "\n",
        "Про использование же методов в каждом конкретном случае можно сделать более строгие выводы:\n",
        "\n",
        "* При использовании FWER оптимально использовать метод Холма (или метод Шидака-Холма в случае независимости статистик) в силу его надежности и в то же время большей мощности по сравнению с другими методами, контролирующими FWER. Но, как мне кажется, полезно сделать оговорку, что если нужно быстро оценить какой-то эксперимент и хочется что-то попроще, то при условии, что сравниваемых гипотез совсем немного (скажем, до 5), вполне нормально использовать метод Бонферрони. Так как при небольшом числе сравнений мы не потеряем сильно в мощности.\n",
        "\n",
        "* Если же мы решили опираться на FDR, то можно использовать как метод Бенджамини-Хохберга, так и метод Бенджамини-Екутиели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCBhB1nPX9_u"
      },
      "source": [
        "#### Симуляция"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvBXtvA0YA2w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from itertools import combinations\n",
        "from scipy import stats\n",
        "from tqdm import tqdm\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import List, Union, Dict, Optional\n",
        "\n",
        "def generate_data(\n",
        "    n_groups: int,\n",
        "    n_per_group: Union[int, List[int]],\n",
        "    mu: List[float],\n",
        "    sigma: Union[float, List[float]] = 1.0,\n",
        "    seed: Optional[int] = None\n",
        ") -> List[np.ndarray]:\n",
        "    \"\"\"Генерирует нормально распределенные данные для групп.\"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    if isinstance(n_per_group, int):\n",
        "        n_per_group = [n_per_group] * n_groups\n",
        "    if isinstance(sigma, (int, float)):\n",
        "        sigma = [sigma] * n_groups\n",
        "\n",
        "    return [\n",
        "        rng.normal(loc=mu[i], scale=sigma[i], size=n_per_group[i])\n",
        "        for i in range(n_groups)\n",
        "    ]\n",
        "\n",
        "def simulate_multiple_testing(\n",
        "    n_runs: int = 1000,\n",
        "    n_groups: int = 3,\n",
        "    n_per_group: int = 30,\n",
        "    effect_size: float = 0.5,\n",
        "    alpha: float = 0.05,\n",
        "    methods: List[str] = [],\n",
        "    seed: Optional[int] = None\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"Симулирует множественное тестирование.\"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    methods = ['none'] if len(methods) == 0 else methods\n",
        "    results = {m: 0 for m in methods}\n",
        "\n",
        "    mu = [0] * n_groups\n",
        "    mu[1] = effect_size  # Только одна группа с эффектом\n",
        "\n",
        "    for _ in tqdm(range(n_runs), desc=\"Симуляция экспериментов\"):\n",
        "        data = generate_data(n_groups, n_per_group, mu, seed=rng.integers(1e6))\n",
        "        for method in methods:\n",
        "            res = run_multiple_comparisons(data, alpha, method)\n",
        "            results[method] += res['rejected'].any()\n",
        "\n",
        "    return {k: v/n_runs for k, v in results.items()}\n",
        "\n",
        "\n",
        "def run_multiple_comparisons(\n",
        "    data: List[np.ndarray],\n",
        "    alpha: float = 0.05,\n",
        "    method: str = 'none'\n",
        ") -> Dict:\n",
        "    \"\"\"Выполняет попарные t-тесты с разными методами поправки.\"\"\"\n",
        "    labels, pvals = [], []\n",
        "    for i, j in combinations(range(len(data)), 2):\n",
        "        _, p = stats.ttest_ind(data[i], data[j], equal_var=False)\n",
        "        labels.append(f\"Группа {i} vs {j}\")\n",
        "        pvals.append(p)\n",
        "\n",
        "    pvals = np.array(pvals)\n",
        "\n",
        "    method_handlers = {\n",
        "        'none': (lambda p, a: p < a, \"Без поправки\"),\n",
        "        'bonferroni_manual': (apply_bonferroni_correction, \"Ручная поправка Бонферрони\"),\n",
        "        'bonferroni_multitest': (lambda p, a: multipletests(p, a, 'bonferroni')[0],\n",
        "                         \"Бонферрони из statsmodels\"),\n",
        "        'holm_manual': (apply_holm_correction, \"Ручная поправка Холма\"),\n",
        "        'holm_multitest': (lambda p, a: multipletests(p, a, 'holm')[0], \"Холм из statsmodels\"),\n",
        "        'sidak_manual': (apply_sidak_correction, \"Ручная поправка Шидака\"),\n",
        "        'sidak_multitest': (lambda p, a: multipletests(p, a, 'sidak')[0], \"Шидак из statsmodels\"),\n",
        "        'bh_manual': (apply_bh_correction, \"Бенджамини-Хохберг (ручн.)\"),\n",
        "        'bh_multitest': (lambda p, a: multipletests(p, a, 'fdr_bh')[0],\n",
        "                         \"Бенджамини-Хохберг (statsmodels)\"),\n",
        "        'by_manual': (apply_by_correction, \"Бенджамини-Екутиели (ручн.)\"),\n",
        "        'by_multitest': (lambda p, a: multipletests(p, a, 'fdr_by')[0],\n",
        "                         \"Бенджамини-Екутиели (statsmodels)\")\n",
        "    }\n",
        "\n",
        "    if method not in method_handlers:\n",
        "        raise ValueError(f\"Неизвестный метод: {method}\")\n",
        "\n",
        "    handler, description = method_handlers[method]\n",
        "    rejected = handler(pvals, alpha)\n",
        "\n",
        "    return {\n",
        "        'labels': labels,\n",
        "        'pvalues': pvals,\n",
        "        'rejected': rejected,\n",
        "        'method': method,\n",
        "        'description': description\n",
        "    }\n",
        "\n",
        "def plot_comparison_results(\n",
        "    results: Dict,\n",
        "    title: str = \"Сравнение методов\",\n",
        "    methods: List[str] = []\n",
        ") -> None:\n",
        "    \"\"\"Визуализирует результаты сравнения методов.\"\"\"\n",
        "    plt.figure(figsize=(14, 7))\n",
        "\n",
        "    methods_order = methods if methods else ['none']\n",
        "    values = [results[m] for m in methods_order]\n",
        "\n",
        "    # Красивые названия для легенды\n",
        "    pretty_names = {\n",
        "        'none': \"Без поправки\",\n",
        "        'bonferroni_manual': \"Бонферрони (ручн.)\",\n",
        "        'bonferroni_multitest': \"Бонферрони (statsmodels)\",\n",
        "        'holm_manual': \"Холм (ручн.)\",\n",
        "        'holm_multitest': \"Холм (statsmodels)\",\n",
        "        'sidak_manual': \"Шидак (ручн.)\",\n",
        "        'sidak_multitest': \"Шидак (statsmodels)\",\n",
        "        'bh_manual': \"BH (ручн.)\",\n",
        "        'bh_multitest': \"BH (statsmodels)\",\n",
        "        'by_manual': \"BY (ручн.)\",\n",
        "        'by_multitest': \"BY (statsmodels)\"\n",
        "    }\n",
        "\n",
        "    ax = sns.barplot(x=[pretty_names[m] for m in methods_order],\n",
        "                    y=values, palette=\"viridis\")\n",
        "\n",
        "    for p in ax.patches:\n",
        "        ax.annotate(f\"{p.get_height():.3f}\",\n",
        "                   (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                   ha='center', va='center', xytext=(0, 10),\n",
        "                   textcoords='offset points')\n",
        "\n",
        "    plt.axhline(0.05, color='red', linestyle='--', label='Уровень α=0.05')\n",
        "    plt.title(title, pad=20)\n",
        "    plt.ylabel(\"Доля отклонений\")\n",
        "    plt.xlabel(\"Метод\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZmmydg8YCo3"
      },
      "outputs": [],
      "source": [
        "sim_results = simulate_multiple_testing(\n",
        "      n_runs=1000,\n",
        "      n_groups=5,\n",
        "      n_per_group=100,\n",
        "      effect_size=0.0,  # Небольшой эффект\n",
        "      alpha=0.05,\n",
        "      methods=['none', 'bonferroni_manual', 'bonferroni_multitest', 'holm_manual',\n",
        "             'holm_multitest', 'sidak_manual', 'sidak_multitest', 'bh_manual',\n",
        "             'bh_multitest', 'by_manual', 'by_multitest'],\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Визуализация\n",
        "plot_comparison_results(\n",
        "    sim_results,\n",
        "    title=\"Сравнение методов контроля\",\n",
        "    methods=['none', 'bonferroni_manual', 'bonferroni_multitest', 'holm_manual',\n",
        "             'holm_multitest', 'sidak_manual', 'sidak_multitest', 'bh_manual',\n",
        "             'bh_multitest', 'by_manual', 'by_multitest']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AInscqj1cv5r"
      },
      "source": [
        "### Учёт поправок при дизайне эксперимента"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXI_Aqagde5q"
      },
      "source": [
        "Сейчас поговорим о том, как учесть проблему множественного тестирования и контроль ошибок на этапе дизайна эксперимента.\n",
        "\n",
        "Обычно при планировании эксперимента мы должны убедиться, что выбранный критерий для оценки подходит, то есть соответствует ожидаемым значениям ошибок I и II рода (желательно также выбрать наиболее мощный критерий для наших данных, но это уже другая история).\n",
        "\n",
        "Для этого, как правило, мы используем исторические данные наших целевых метрик: итеративно случайно делим пользователей на control и treatment группы с учетом заранее рассчитанного sample size, рассчитываем значения p-value выбранным критерием и считаем ошибку I рода (или добавляем эффект к treatment-группе и считаем ошибку II рода).\n",
        "\n",
        "В нашем случае мы заранее знаем, сколько тестовых групп у нас будет и, следовательно, сколько гипотез мы будем проверять. Поэтому далее проделаем следующий шаги:\n",
        "\n",
        "1. Для начала необходимо выбрать метод котонроля ошибки I рода: FWER / FDR /  etc.\n",
        "\n",
        "2. По аналогии с обычным экспериментом возьмем данные по интересующей нас метрике за предыдущий период\n",
        "3. Затем оценим, какой размер выборки необходим для детекции заданного эффекта\n",
        "\n",
        "4. Разделим пользователей на группы и оценим контроль выбранной метрики\n",
        "\n",
        "5. При необходимости скорректируем sample size с учетом желаемой мощности"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TPgCEcma3jn"
      },
      "source": [
        "#### Сетап эксперимента"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-SiP-KNhy_e"
      },
      "source": [
        "Пусть мы имеем некоторую метрику с нормальным распределением с параметрами $\\mu$ = 10, $\\sigma$ = 1, $N$=1.000.000. Ожидаемый минимальный эффект, который хотим детектировать – 0.5%. В эксперименте у нас будет 5 групп (1 контрольная и 4 тестовых), мы хотим делать сравнения \"все против всех\", то есть сравнивать каждую группу с каждой."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLoCbOnW55WX"
      },
      "source": [
        "##### Функции"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QB2JO3zq57B1"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.power import TTestIndPower\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "from typing import List, Union, Dict, Optional\n",
        "\n",
        "def calculate_sample_size(\n",
        "    effect_size: float,\n",
        "    alpha: float = 0.05,\n",
        "    power: float = 0.8,\n",
        "    ratio: float = 1.0,\n",
        "    alternative: str = 'two-sided'\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Расчет необходимого размера выборки для t-теста.\n",
        "\n",
        "    Parameters:\n",
        "        effect_size (float): ожидаемый размер эффекта (Cohen's d).\n",
        "        alpha (float): уровень значимости.\n",
        "        power (float): требуемая мощность.\n",
        "        ratio (float): соотношение размеров групп (n2/n1).\n",
        "        alternative (str): 'two-sided' или 'larger'/'smaller' для одностороннего теста.\n",
        "\n",
        "    Returns:\n",
        "        int: необходимый размер выборки для каждой группы.\n",
        "    \"\"\"\n",
        "    analysis = TTestIndPower()\n",
        "    result = analysis.solve_power(\n",
        "        effect_size=effect_size,\n",
        "        power=power,\n",
        "        alpha=alpha,\n",
        "        ratio=ratio,\n",
        "        alternative=alternative\n",
        "    )\n",
        "    # Обычно результат — это размер группы n1, можно умножить на ratio для n2\n",
        "    n1 = int(np.ceil(result))\n",
        "    n2 = int(np.ceil(n1 * ratio))\n",
        "    return n1, n2\n",
        "\n",
        "def method_without_correct(p_values: List[float], alpha: float = 0.05):\n",
        "    \"\"\"The function returns the comparison result without corrections\"\"\"\n",
        "\n",
        "    res = (np.array(p_values) <= alpha).astype(int)\n",
        "    return res\n",
        "\n",
        "def method_bonferroni(p_values: List[float], alpha: float = 0.05):\n",
        "    \"\"\"The function returns the comparison result with Bonferroni correction\"\"\"\n",
        "\n",
        "    return (multipletests(p_values, alpha=alpha, method=\"bonferroni\")[0]).astype(int)\n",
        "\n",
        "\n",
        "def method_holm(p_values: List[float], alpha: float = 0.05):\n",
        "    \"\"\"The function returns the comparison result with Holm correction\"\"\"\n",
        "\n",
        "    return (multipletests(p_values, alpha=alpha, method=\"holm\")[0]).astype(int)\n",
        "\n",
        "\n",
        "def method_benjamini_hochberg(p_values: List[float], alpha: float = 0.05):\n",
        "    \"\"\"The function returns the comparison result with Benjamini-Hochberg correction\"\"\"\n",
        "\n",
        "    return (multipletests(p_values, alpha=alpha, method=\"fdr_bh\")[0]).astype(int)\n",
        "\n",
        "def get_barplot_errors(\n",
        "    df: pd.DataFrame,\n",
        "    methods: dict,\n",
        "    mu: float,\n",
        "    std: float,\n",
        "    effect: float,\n",
        "    sample_size: int,\n",
        "    n_groups: int,\n",
        "    n_iter: int,\n",
        "    type_error: str\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Моделирует и визуализирует ошибки в множественных тестах при использовании различных методов поправки.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame с исходными метриками, содержащий колонку 'metric'.\n",
        "        methods (dict): словарь методов, где ключ — название метода, значение — функция, реализующая поправку.\n",
        "        mu (float): базовое среднее значение для генерации данных.\n",
        "        std (float): стандартное отклонение для генерации данных.\n",
        "        effect (float): размер эффекта, добавляемый в первую группу, чтобы моделировать истинное влияние.\n",
        "        sample_size (int): размер выборки для каждой группы.\n",
        "        n_groups (int): число групп для сравнения.\n",
        "        n_iter (int): количество итераций моделирования.\n",
        "        type_error (str): тип ошибки для анализа ('fwer', 'fwer II' или другое).\n",
        "    \"\"\"\n",
        "    # Инициализация словарей для хранения результатов ошибок\n",
        "    fwer = {method_name: [] for method_name in methods}\n",
        "    error_type_II = {method_name: [] for method_name in methods}\n",
        "    fwtr = {method_name: [] for method_name in methods}\n",
        "\n",
        "    # Извлечение данных из DataFrame\n",
        "    values = df[\"metric\"].values\n",
        "\n",
        "    # Создаем словарь для хранения данных по группам\n",
        "    groups_bucket = {num: [] for num in range(1, n_groups + 1)}\n",
        "\n",
        "    # Объявляем словарь для хранения результатов по каждому методу\n",
        "    result = {method: {\"first\": [], \"second\": []} for method in methods}\n",
        "\n",
        "    # Генерация всех уникальных пар групп с помощью itertools.combinations\n",
        "    group_pairs = list(itertools.combinations(range(1, n_groups + 1), 2))\n",
        "\n",
        "    # Основной цикл моделирования\n",
        "    for _ in tqdm(range(n_iter)):\n",
        "        # Генерация данных для каждой группы\n",
        "        for num in groups_bucket:\n",
        "            if num == 1:\n",
        "                # Первая группа тестовая\n",
        "                group = np.random.choice(values, int(sample_size), replace=True)\n",
        "            else:\n",
        "                # Остальные — контрольные\n",
        "                group = np.random.choice(values * effect, int(sample_size), replace=True)\n",
        "            groups_bucket[num] = group\n",
        "\n",
        "        # Проведение всех попарных t-тестов\n",
        "        pvalues = []\n",
        "        for grp1, grp2 in group_pairs:\n",
        "            _, pvalue = stats.ttest_ind(groups_bucket[grp1], groups_bucket[grp2])\n",
        "            pvalues.append(pvalue)\n",
        "\n",
        "        # Анализ результатов по каждому методу\n",
        "        for method, func in methods.items():\n",
        "            # Применение метода к списку p-value\n",
        "            adjusted = func(pvalues)\n",
        "\n",
        "            # Расчет мощности и ошибок\n",
        "            result[method][\"first\"].append(np.mean(adjusted[4:]))\n",
        "            result[method][\"second\"].append(1 - np.mean(adjusted[:4]))\n",
        "\n",
        "    # После всех итераций вычисляем средние показатели\n",
        "    for method, params in result.items():\n",
        "        # Вероятность хотя бы одной ошибки (FWER)\n",
        "        fwer[method] = np.mean(np.array(params[\"first\"]) > 0)\n",
        "        # Вероятность пропуска истинных гипотез (ошибка 2-го рода)\n",
        "        fwtr[method] = np.mean(np.array(params[\"second\"]) > 0)\n",
        "        # Средняя ошибка 2-го рода\n",
        "        error_type_II[method] = np.mean(params[\"second\"])\n",
        "\n",
        "    # Настройка отображения в зависимости от типа ошибки\n",
        "    if type_error == \"fwer\":\n",
        "        errors = fwer\n",
        "        ylabel = \"FWER\"\n",
        "        label = \"alpha=0.05\"\n",
        "        xline = 0.05\n",
        "    elif type_error == \"fwer II\":\n",
        "        errors = fwtr\n",
        "        ylabel = \"FWER II\"\n",
        "        label = \"beta=0.2\"\n",
        "        xline = 0.2\n",
        "    else:\n",
        "        errors = error_type_II\n",
        "        ylabel = \"Error Type II\"\n",
        "        label = \"beta=0.2\"\n",
        "        xline = 0.2\n",
        "\n",
        "    # Построение графика\n",
        "    sns.set(style=\"darkgrid\")\n",
        "    fig, ax = plt.subplots(figsize=(14, 7))\n",
        "    plt.bar(range(len(errors)), list(errors.values()), align=\"center\")\n",
        "    plt.xticks(range(len(errors)), list(errors.keys()))\n",
        "    ax.hlines(xline, -1, len(errors), linestyles='--', label=label, color='r')\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.xlabel(\"Методы\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u2AMAsJ57JG"
      },
      "source": [
        "##### Симуляция"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhpxW6JJidiC"
      },
      "outputs": [],
      "source": [
        "mu = 10\n",
        "std = 1\n",
        "effect = 1.005\n",
        "size_group = 100_000\n",
        "n_groups = 5\n",
        "\n",
        "alpha = 0.05\n",
        "beta = 0.2\n",
        "\n",
        "df = pd.DataFrame({\"metric\": np.random.normal(mu, std, size_group)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USqnJwAaixqt"
      },
      "source": [
        "Рассчитаем минимальный объем выборки, необходимый для детекции заданного эффекта с учетом распределения метрики."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1G1U_-qpfa34"
      },
      "outputs": [],
      "source": [
        "n1, n2 = calculate_sample_size(effect_size=0.05, alpha=0.05, power=0.8, ratio=1)\n",
        "print(f\"Для равных групп необходимо по {n1} участников в каждой группе.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNDfl2L4j0So"
      },
      "source": [
        "Получаем, что для детекции эффекта в 0.5% на одну группу необходимо ~6.3K объектов.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiEl8nAqdKSF"
      },
      "outputs": [],
      "source": [
        "methods = {\n",
        "    \"without_correct\": method_without_correct,\n",
        "    \"bonferroni\": method_bonferroni,\n",
        "    \"holm\": method_holm,\n",
        "    \"benjamini-hochberg\": method_benjamini_hochberg,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EVl6bRckNbo"
      },
      "outputs": [],
      "source": [
        "get_barplot_errors(df=df, methods=methods, mu=mu, std=std, effect=effect,\n",
        "                       sample_size=n1, n_groups=n_groups, n_iter=1000, type_error=\"fwer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93QDewgQmy1X"
      },
      "outputs": [],
      "source": [
        "get_barplot_errors(df=df, methods=methods, mu=mu, std=std, effect=effect,\n",
        "                       sample_size=6300, n_groups=5, n_iter=1000, type_error=\"error_type_II\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZvmeDSRoUqy"
      },
      "source": [
        "1. Видим, что поправки хорошо контролируют FWER (за исключением метода Бенджамини-Хохберга, так как он гарантирует только контроль FDR).\n",
        "\n",
        "2. Поправки ожидаемо снижают мощность эксперимента, в особенности методы Бонферрони и Холма, контролирующие FWER. Средняя ошибка II рода при всех сравнениях для методов с поправками выше ожидаемой 0.2.\n",
        "\n",
        "  Но при возможности нам ничего не мешает скорректировать ошибку II рода до ожидаемых значений для выбранного метода поправок."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp4kMHtIqYtG"
      },
      "source": [
        "Мы знаем, что можем уменьшить ошибку путем увеличения размера выборки. Это следует из формулы для расчета размера выборки для случая t-test:\n",
        "\n",
        "$$\n",
        "N = \\frac{\\left( \\Phi^{-1}_{(1 - \\frac{\\alpha}{2})} + \\Phi^{-1}_{(1 - \\beta)} \\right)^2}{\\text{mde}^2} \\times \\sigma^2\n",
        "$$\n",
        "\n",
        "Посмотрим на формулу для расчета минимального размера выборки и вспомним, что наши поправки корректируют значения p-value. Значит, мы можем скорректировать уровни значимости при расчете sample size.\n",
        "\n",
        "[Существуют](https://link.springer.com/article/10.1007/s10732-020-09454-w) следующие подходы для коррекции sample size при использовании поправок на множественное тестирование:\n",
        "\n",
        "1. Расчет минимального размера выборки на основе наименее благоприятных условий: мы можем рассчитать размер выборки с учетом заданной вероятности ошибок II рода так, чтобы тест с наиболее строгим уровнем значимости $\\alpha$ будет иметь необходимую мощность. То есть фактически самый скорректированный уровень значимости генерируется поправкой Бонферрони: в этом случае нужно разделить значение $\\alpha$ на число сравнений m, то есть $\\alpha_i$  = $\\alpha_i / m$. Это будет гарантировать заданную мощность теста;\n",
        "\n",
        "2. Другой подход заключается в том, чтобы средняя (или медианная) мощность тестов поддерживалась на заданном уровне. Для случая медианной мощности достаточно $\\alpha$ разделить на $m / 2$. Для поддержания средней мощности на заданном уровне необходимо итеративно посчитать sample size с фиксированными заданными параметрами, разделив заданный уровень значимости $\\alpha$ на упорядоченный по возрастанию список числа гипотез и усреднить значение sample size\n",
        "\n",
        "$$\n",
        "N = \\frac{\\sum \\left( N \\left[ \\alpha / i \\right] \\right)}{m} \\quad \\text{, где } i \\in [1;m]\n",
        "\\quad N \\text{ – функция для расчета sample size с фиксированными параметрами, за исключением } \\alpha\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0LTCKGJtF2S"
      },
      "source": [
        "Используем на практике оба подхода для демонстрации коррекции sample size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpvfjc5Q5r4u"
      },
      "outputs": [],
      "source": [
        "combinations = len(list(itertools.combinations(range(1, n_groups + 1), 2)))\n",
        "\n",
        "## 1 метод\n",
        "\n",
        "n1_first_var, n2_first_var = calculate_sample_size(effect_size=0.05, alpha= 0.05 / combinations, power=0.8, ratio=1)\n",
        "print(f'Для первого метода необходимо {n1_first_var} человек на каждую группу, что на {round( (n1_first_var - n1) * 100.0 / n1, 1)}% больше первоначального\\n{\"*\"*50}')\n",
        "get_barplot_errors(df=df, methods=methods, mu=mu, std=std, effect=effect,\n",
        "                       sample_size=n1_first_var, n_groups=5, n_iter=1000, type_error=\"error_type_II\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkMuB3p9uGz-"
      },
      "outputs": [],
      "source": [
        "## 2 метод\n",
        "combinations = len(list(itertools.combinations(range(1, n_groups + 1), 2)))\n",
        "n_values = list()\n",
        "\n",
        "for i in range(1, combinations+1):\n",
        "    n_values.append(calculate_sample_size(effect_size=0.05, alpha= 0.05 / i, power=0.8, ratio=1))\n",
        "print(f'Для второго метода необходимо {np.mean(n_values)} человек на каждую группу, что на {round( (np.mean(n_values) - n1) * 100.0 / n1, 1)}% больше первоначального\\n{\"*\"*50}')\n",
        "\n",
        "get_barplot_errors(df=df, methods=methods, mu=mu, std=std, effect=effect,\n",
        "                       sample_size=np.mean(n_values), n_groups=5, n_iter=1000, type_error=\"error_type_II\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9yRF_YjvfyL"
      },
      "source": [
        "В таких случаях мы получаем ожидаемый уровень ошибок II рода.\n",
        "\n",
        "На практике при использовании методов контроля FWER (в том числе метода Холма) может быть более оптимальным использование поправки на размер выборки с учетом более консервативного метода коррекции $\\alpha$(первый вариант). Это будет гарантировать заданный уровень ошибок II рода.\n",
        "\n",
        "Но стоит подчеркнуть, что для оценки мощности теста мы использовали среднее значение ошибки II рода, но для еще большей мощности также можем опираться на аналог FWER для ошибки II рода – вероятность допустить хотя бы одну ошибку II рода. Это потребует еще большего количества данных, но если у нас есть возможность собрать больше данных – почему бы не сделать тест мощнее.\n",
        "\n",
        "В этом случае для надежности можно делить $\\alpha$ не просто на количество сравнений, а на количество сравнений в квадрате, то есть в нашем случае на 10^2 = 100 (это не обосновано математически, но получено опытным путем)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mERIJaAHtIgf"
      },
      "outputs": [],
      "source": [
        "combinations = len(list(itertools.combinations(range(1, n_groups + 1), 2)))\n",
        "\n",
        "## 1 метод\n",
        "\n",
        "n1_first_var, n2_first_var = calculate_sample_size(effect_size=0.05, alpha= 0.05 / combinations ** 2, power=0.8, ratio=1)\n",
        "print(f'Для этого метода необходимо {n1_first_var} человек на каждую группу, что на {round( (n1_first_var - n1) * 100.0 / n1, 1)}% больше первоначального\\n{\"*\"*50}')\n",
        "get_barplot_errors(df=df, methods=methods, mu=mu, std=std, effect=effect,\n",
        "                       sample_size=n1_first_var, n_groups=5, n_iter=1000, type_error=\"fwer II\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCLfckpxlnI_"
      },
      "source": [
        "##### Распределение трафика по группам"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjZA1lGOmogO"
      },
      "source": [
        "Тем не менее, можно и снизить число пользователей для тестирования благодаря более хитрому распределению пользователей по группам.\n",
        "\n",
        "При наличии одной контрольной группы и $k$ экспериментальных групп, с общим числом пользователей $N$, целью является минимизация дисперсии статистики (предположим t-test):\n",
        "\n",
        "\n",
        "\n",
        "$$\n",
        "\\Large t = \\frac{\\bar{X} - \\bar{Y}}{\\sqrt{\\frac{s_X^2}{n} + \\frac{s_Y^2}{m}}}\n",
        "$$\n",
        "\n",
        "что сводится к минимизации следующего функционала:\n",
        "\n",
        "$$\\min_{n,m} \\left( \\frac{1}{n} + \\frac{k}{m} \\right)$$\n",
        "\n",
        "При условии, что все пользователи распределены ($n + km = N$) оптимальными размерами групп $n$ (контрольная) и $m$ (каждая экспериментальная) будут:\n",
        "$$m = \\frac{N}{k + \\sqrt{k}}$$\n",
        "$$n = \\frac{N}{1 + \\sqrt{k}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh9bBAB4C-dY"
      },
      "source": [
        "Рассмотрим задачу минимизации функции\n",
        "$$\n",
        "f(n, m) = \\frac{1}{n} + \\frac{1}{m}\n",
        "$$\n",
        "при условии\n",
        "$$\n",
        "n + k m = N,\n",
        "$$\n",
        "\n",
        "\n",
        "1. Подставим выражение для n $n = N - k m.$\n",
        ", тогда получаем функцию от m:\n",
        "$$\n",
        "f(m) = \\frac{1}{N - k m} + \\frac{1}{m}.\n",
        "$$\n",
        "\n",
        "2. Чтобы найти минимальное значение $f(m)$ нужно взять производную по $m$ и приравнять к нулю для поиска стационарных точек:\n",
        "\n",
        "$$\n",
        "f'_{m}(m) = \\frac{k}{(N - k m)^2} - \\frac{1}{m^2} = 0\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{1}{m^2} = \\frac{k}{(N - k m)^2}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{N - k m}{m} = \\pm \\sqrt{k}\n",
        "$$\n",
        "Рассмотрим положительный корень (так как $n$,$m$ > 0 ):\n",
        "\n",
        "$$\n",
        "\\frac{N - k m}{m} = \\sqrt{k}\n",
        "$$\n",
        "\n",
        "$$\n",
        "N = m (\\sqrt{k} + k)\n",
        "$$\n",
        "\n",
        "$$\n",
        "m = \\frac{N}{\\sqrt{k} + k}\n",
        "$$\n",
        "\n",
        "Аналогично, найдём $n$:\n",
        "\n",
        "$$\n",
        "n = N - k m\n",
        "$$\n",
        "\n",
        "$$\n",
        "n = N - k \\cdot \\frac{N}{\\sqrt{k} + k}\n",
        "$$\n",
        "\n",
        "$$\n",
        "n= N \\left( 1 - \\frac{k}{\\sqrt{k} + k} \\right)\n",
        "$$\n",
        "\n",
        "$$\n",
        "n=N \\frac{\\sqrt{k}}{\\sqrt{k} + k}\n",
        "$$\n",
        "\n",
        "$$\n",
        "n = \\frac{N}{\\sqrt{k}+1}\n",
        "$$\n",
        "\n",
        "Итак, окончательное решение:\n",
        "$$\n",
        "\\boxed{\n",
        "\\begin{aligned}\n",
        "m &= \\frac{N}{\\sqrt{k} + k}, \\\\\n",
        "n &= \\frac{N \\sqrt{k}}{\\sqrt{k} + 1}.\n",
        "\\end{aligned}\n",
        "}\n",
        "$$\n",
        "\n",
        "Это — оптимальные значения для минимизации функции при заданных условиях."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUvTnG90daBO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from tqdm import tqdm\n",
        "\n",
        "def calculate_mde(n_control, n_treatment, alpha=0.05, power=0.8):\n",
        "    \"\"\"Вычисляет минимальный обнаруживаемый эффект (MDE) для t-теста\"\"\"\n",
        "    df = n_control + n_treatment - 2\n",
        "    t_alpha = stats.t.ppf(1 - alpha/2, df)\n",
        "    t_beta = stats.t.ppf(power, df)\n",
        "\n",
        "    pooled_var = 1  # предполагаем unit variance для стандартизации\n",
        "    se = np.sqrt(pooled_var * (1/n_control + 1/n_treatment))\n",
        "\n",
        "    return (t_alpha + t_beta) * se\n",
        "\n",
        "def optimal_allocation(N, k):\n",
        "    \"\"\"Вычисляет оптимальное распределение пользователей\"\"\"\n",
        "    m = N / (k + np.sqrt(k))  # размер каждой экспериментальной группы\n",
        "    n = N / (1 + np.sqrt(k))  # размер контрольной группы\n",
        "    return int(round(n)), int(round(m))\n",
        "\n",
        "def uniform_allocation(N, k):\n",
        "    \"\"\"Равномерное распределение пользователей\"\"\"\n",
        "    total_groups = k + 1\n",
        "    n = N // total_groups\n",
        "    m = n\n",
        "    return n, m\n",
        "\n",
        "def simulate_mde_comparison(max_k=10, N=100000, alpha=0.05, power=0.8):\n",
        "    \"\"\"Сравнивает MDE для оптимального и равномерного распределения\"\"\"\n",
        "    k_values = range(1, max_k+1)\n",
        "    mde_optimal = []\n",
        "    mde_uniform = []\n",
        "    ratio_improvement = []\n",
        "\n",
        "    for k in tqdm(k_values, desc=\"Calculating MDEs\"):\n",
        "        # Оптимальное распределение\n",
        "        n_opt, m_opt = optimal_allocation(N, k)\n",
        "        mde_opt = calculate_mde(n_opt, m_opt, alpha, power)\n",
        "        mde_optimal.append(mde_opt)\n",
        "\n",
        "        # Равномерное распределение\n",
        "        n_uni, m_uni = uniform_allocation(N, k)\n",
        "        mde_uni = calculate_mde(n_uni, m_uni, alpha, power)\n",
        "        mde_uniform.append(mde_uni)\n",
        "\n",
        "        # Улучшение в %\n",
        "        improvement = (mde_uni - mde_opt) / mde_uni * 100\n",
        "        ratio_improvement.append(improvement)\n",
        "\n",
        "    return k_values, mde_optimal, mde_uniform, ratio_improvement\n",
        "\n",
        "def plot_results(k_values, mde_optimal, mde_uniform, ratio_improvement):\n",
        "    \"\"\"Визуализирует результаты симуляции\"\"\"\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # График MDE\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(k_values, mde_optimal, 'o-', label='Оптимальное распределение')\n",
        "    plt.plot(k_values, mde_uniform, 's-', label='Равномерное распределение')\n",
        "    plt.xlabel('Количество экспериментальных групп (k)')\n",
        "    plt.ylabel('Minimum Detectable Effect (MDE)')\n",
        "    plt.title('Сравнение MDE для разных распределений\\nN=100,000, α=0.05, power=80%')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # График улучшения\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(k_values, ratio_improvement, 'd-', color='green')\n",
        "    plt.xlabel('Количество экспериментальных групп (k)')\n",
        "    plt.ylabel('Улучшение MDE (%)')\n",
        "    plt.title('Процент улучшения MDE\\nоптимальным распределением')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Запуск симуляции\n",
        "\n",
        "k_values, mde_opt, mde_uni, ratio_imp = simulate_mde_comparison(max_k=10, N=10000)\n",
        "\n",
        "# Вывод результатов\n",
        "print(\"Результаты сравнения:\")\n",
        "for k, opt, uni, imp in zip(k_values, mde_opt, mde_uni, ratio_imp):\n",
        "    print(f\"k={k}: MDE оптимальное={opt:.4f}, MDE равномерное={uni:.4f}, улучшение={imp:.1f}%\")\n",
        "\n",
        "# Визуализация\n",
        "plot_results(k_values, mde_opt, mde_uni, ratio_imp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQd4CR9i3TiX"
      },
      "source": [
        "### На какую метрику смотреть?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHh68vhO3TiX"
      },
      "source": [
        "В реальности почти во всех A/B-тестах у нас всегда есть множество метрик. И это создаёт определённую проблему для аналитиков и продуктовых менеджеров: как правильно интерпретировать результаты теста, когда на вас обрушивается так много показателей.\n",
        "\n",
        "Для этого существуют разные подходы. Обычно в представлении менеджеров и аналитиков есть несколько ключевых метрик, на которые они смотрят в первую очередь. Часто это что-то вроде интуитивного фильтра: приносит ли новая фича больше прибыли или улучшает ли она основную бизнес-метрику.\n",
        "\n",
        "Помимо этого, можно использовать и другие подходы, например, более формальные статистические методы для многократного тестирования, которые помогают контролировать ошибки первого и второго рода. Одним из таких инструментов является фреймворк от Spotify, о котором мы сейчас и поговорим.\n",
        "\n",
        "https://docs.google.com/presentation/d/1v7PzCJONgs8wFC6D61VXhpF6vIv-lPNBfxbF0NQP1hg/edit?slide=id.p#slide=id.p"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "zBbI-EN60bQ-",
        "XtXVt72pzkPW",
        "LDNN4C1Hz-RS",
        "O03f0OHK8YEL",
        "BuNlSBnTetoD",
        "GMV63YfHe5m7",
        "11DHqzi4iLmx",
        "maH8Jft3iW4u",
        "nBUj4x0Gs-UQ",
        "4lg1gJCxiMNW",
        "mkrlUbimiMi-",
        "sfQkJ58-twOg",
        "iQLkPXCoa9bS",
        "tCBhB1nPX9_u",
        "AInscqj1cv5r",
        "1TPgCEcma3jn",
        "eLoCbOnW55WX",
        "4u2AMAsJ57JG",
        "rCLfckpxlnI_"
      ],
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
# Lesson 07 — Multi-Armed Bandits

## Overview
Многорукие бандиты помогают балансировать между исследованием и эксплуатацией в условиях неопределённости. Урок вводит ключевые алгоритмы (ε-greedy, Softmax, UCB, Thompson Sampling) и обсуждает, когда они применяются для онлайн-оптимизации.

## Learning goals
- Понять дилемму exploration vs exploitation и её влияние на принятие решений.
- Освоить базовую механику алгоритмов многоруких бандитов и их отличия.
- Увидеть примеры применения MAB в бизнес-практиках.

## Session materials
- [Lecture notebook](lecture.ipynb)

## References
### Основные источники
1. Ноутбук [Яна Пиле](https://www.linkedin.com/in/ian-pilé-a6078a75/) (материалы выступления WB)
2. [Многорукие бандиты в задаче ритейла](https://habr.com/ru/companies/X5Tech/articles/783390/)

### Дополнительные материалы
- [Survey of multi-armed bandits](https://arxiv.org/pdf/1904.07272)
- [Графический разбор и реализация MAB](https://github.com/raffg/multi_armed_bandit/tree/master)
- [Bayesian AB test (пример реализации)](https://github.com/Arngren/bayesian-ab-test)
